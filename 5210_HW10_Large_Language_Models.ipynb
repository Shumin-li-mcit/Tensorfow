{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shumin-li-mcit/Tensorfow/blob/main/5210_HW10_Large_Language_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring GPT-3\n",
        "\n",
        "In this homework assignment we will walk you through how to use GPT-3 a large pre-trained neural language model developed by OpenAI.  \n",
        "\n",
        "You will learn about the following topics:\n",
        "* Prompts and completions.  You should observe that the the quality of the text generated is high quality, but not necessarially factually accurate.\n",
        "* Probabilities.  You'll learn how to inspect probabilities assigned to words in the model's output.\n",
        "* Few shot learning.  We'll see an example of few-shot learning with a small handful of examples.\n",
        "* Zero shot learning.  We will explore the zero-shot capabilities of pre-trained LMs.  You'll design zero-shot prompts for\n",
        "1. summarization\n",
        "2. question-answering\n",
        "3. simplification\n",
        "4. translation\n",
        "* How to fine tune a model.  You will learn how to fine-tune GPT-3 to take a Wikipedia infobox as input and generate the text of a biography as its ouput.  You'll then write your own code to do the reverse task – given a biography, extract the  attributes and values in the style of a Wikipedia infobox.\n",
        "\n",
        "\n",
        "\n",
        "# Prompt Completion\n",
        "\n",
        "As a warm-up we'll have you play with [the OpenAI Playground](https://beta.openai.com/playground).  Try inputting this prompt:\n",
        "\n",
        "> One of my favorite professors at the University of Pennsylvania is\n",
        "\n",
        "And the click the \"Submit\" button to generate a completion.\n",
        "\n",
        "Copy and paste the text below (including your prompt).\n",
        "\n",
        "You might notice that the text that GPT-3 generates ends mid-sentence.  GPT-3 will generate text until it either generates a special \"stop sequence\" token `<|endoftext|>`, or it outputs the number of tokens specified by the `maximum length` variable.\n",
        "You can press Submit again to have it continue generatin, or you can increase the max length variable in the sliderbar on the right."
      ],
      "metadata": {
        "id": "pjqy7heO706G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "favorite_professor_completion_1 = \"\"\"\n",
        "One of my favorite professors at the University of Pennsylvania is \\\n",
        "\n",
        "Dr. Sarah Johnson. She was my professor for a course on contemporary American literature. Dr. Johnson's passion for literature was infectious, and she always made the class engaging and thought-provoking.\n",
        "\n",
        "She had a deep knowledge and understanding of the texts we studied, and she would often bring in real-life examples and current events to help us relate to the material. This made the literature come alive and helped us see its relevance in our own lives.\n",
        "\n",
        "Dr. Johnson was also incredibly approachable and always made time for her students. She encouraged open discussions and welcomed different perspectives, which created a collaborative and inclusive learning environment.\n",
        "\n",
        "One aspect I really appreciated about Dr. Johnson was her ability to challenge us intellectually while still providing support and guidance. She pushed us to think critically and analyze the texts in depth, but she was always there to provide further explanation or clarity when needed.\n",
        "\n",
        "Her teaching style was dynamic, incorporating various methods such as group discussions, multimedia presentations, and interactive activities. This kept us engaged and motivated to participate actively in our learning.\n",
        "\n",
        "Overall, Dr. Sarah Johnson was not only an exceptional professor but also a mentor who genuinely cared about her students' growth and success. Her enthusiasm for literature was contagious, and she played a significant role in shaping my love for the subject.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZwhSf4Af79Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-3 generates fluent text, but it is not always grounded in fact.  Let's do a Google search for the person that GPT-3 generated as your favorite professor and check\n",
        "* Are they actually a professor?\n",
        "* Where do they work?"
      ],
      "metadata": {
        "id": "nhYnYplw8K4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the professor's name\n",
        "professor_name_1 = \"Sarah Johnson\"\n",
        "\n",
        "# Do a Google search and answer these questions\n",
        "actually_a_professor_1 = True\n",
        "\n",
        "# Insitituion where they work\n",
        "instituion_1 = \"UC San Diego\""
      ],
      "metadata": {
        "id": "X8-RRIm8-W_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it generates its completions, GPT-3 generates each new word/token according to its probability distribution.  It draws each word at random in proportion to its propability.  That randomness means that it can generate different completions. You can re-generate and get different completions each time.\n",
        "\n",
        "Generate another 4 completions for the professor prompt:\n",
        "\n",
        "> One of my favorite professors at the University of Pennsylvania is\n",
        "\n",
        "and do Google searches for them.\n",
        "\n",
        "*Tip: You can generate another response with the Regenerate button to the right of the Submit button.  The Regenerate button has a recycle symbol on it.*"
      ],
      "metadata": {
        "id": "37sJsYna_jRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "favorite_professor_completion_2 = \"\"\"\n",
        "Professor John Smith. He is an exceptional teacher who has a deep knowledge and passion for his subject, which is economics. What sets him apart from other professors is his ability to make complex concepts easy to understand through real-life examples and engaging class discussions.\n",
        "\n",
        "Professor Smith's teaching style is dynamic and interactive. He encourages student participation and creates a supportive learning environment where everyone feels comfortable sharing their thoughts and asking questions. He is always open to different perspectives and encourages critical thinking, which has greatly enhanced my learning experience.\n",
        "\n",
        "Another aspect that I admire about Professor Smith is his dedication to his students' success. He is always available for extra help and provides feedback that is constructive and helpful. He genuinely cares about his students' progress and goes above and beyond to ensure that everyone is grasping the material.\n",
        "\n",
        "Furthermore, Professor Smith's enthusiasm for economics is contagious. He brings energy and excitement to every class, which makes the subject matter even more interesting. His lectures are not only informative but also engaging and enjoyable.\n",
        "\n",
        "Overall, Professor John Smith is an outstanding professor who has had a significant impact on my academic journey at the University of Pennsylvania. His expertise, teaching style, and dedication to students' success make him one of my favorite professors. I feel fortunate to have had the opportunity to learn from him and\n",
        "\"\"\"\n",
        "\n",
        "favorite_professor_completion_3 = \"\"\"\n",
        "Dr. Jane Smith. She is an incredibly knowledgeable and inspiring professor in the Department of Psychology. Dr. Smith has a unique teaching style that makes complex concepts easy to understand and engage with.\n",
        "\n",
        "What sets Dr. Smith apart is her passion for the subject matter and genuine interest in her students' learning. She goes above and beyond to ensure that everyone in the class feels included and valued. Dr. Smith encourages open discussions and creates a supportive learning environment where students feel comfortable sharing their thoughts and ideas.\n",
        "\n",
        "In addition to her teaching abilities, Dr. Smith is also actively involved in research and has published numerous articles in prestigious journals. Her expertise and experience in the field of psychology enrich her lectures and provide real-world examples to illustrate theoretical concepts.\n",
        "\n",
        "Outside the classroom, Dr. Smith is approachable and always willing to provide guidance and support to her students. She is known for her willingness to meet one-on-one with students to discuss academic or career-related concerns. Dr. Smith truly cares about the success and well-being of her students, and her mentorship has had a significant impact on my academic journey.\n",
        "\n",
        "Overall, Dr. Jane Smith is an exceptional professor who combines her expertise, passion, and dedication to create a memorable and valuable learning experience. She has been instrumental in shaping my education at the\n",
        "\"\"\"\n",
        "\n",
        "favorite_professor_completion_4 = \"\"\"\n",
        "Dr. John Smith. He teaches political science and is known for his engaging lectures and passion for the subject. \\\n",
        "Dr. Smith has a unique ability to break down complex concepts and make them accessible to all students. \\\n",
        "He encourages critical thinking and fosters an inclusive and interactive classroom environment. \\\n",
        "Additionally, he is always available to answer questions and provide guidance outside of class. \\\n",
        "Dr. Smith's dedication to his students' learning and his genuine enthusiasm for the subject make him a standout professor at the University of Pennsylvania.\n",
        "\"\"\"\n",
        "\n",
        "favorite_professor_completion_5 = \"\"\"\n",
        "One of my favorite professors at the University of Pennsylvania is Dr. Anthony W. Lee. \\\n",
        "He is a professor in the Department of Communication within the Annenberg School for Communication. \\\n",
        "Dr. Lee is an amazing teacher and mentor who is always willing to help his students and give them the best advice. \\\n",
        "He also has a great sense of humor which makes his classes a lot of fun. He is an expert in the communication field, \\\n",
        "and his classes are always informative and engaging. He encourages his students to think critically and to challenge their own assumptions. \\\n",
        "His enthusiasm for teaching and commitment to his students make him a great professor.\n",
        "\"\"\"\n",
        "\n",
        "# Do a Google search for these professors\n",
        "\n",
        "professor_name_2 = \"John Smith\"\n",
        "actually_a_professor_2 = True\n",
        "instituion_2 = \"Upenn CIS\"\n",
        "\n",
        "professor_name_3 = \"Jane Smith\"\n",
        "actually_a_professor_3 = True\n",
        "instituion_3 = \"UMN Psychology\"\n",
        "\n",
        "professor_name_4 = \"John Smith\"\n",
        "actually_a_professor_4 = True\n",
        "instituion_4 = \"Upenn CIS\"\n",
        "\n",
        "professor_name_5 = \"Anthony W. Lee\"\n",
        "actually_a_professor_5 = True\n",
        "instituion_5 = \"Arkansas Tech University\""
      ],
      "metadata": {
        "id": "zex_KrxrAVGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probabilities\n",
        "\n",
        "Just like with the n-gram language models that we stuided earlier in the course, neural language models like GPT-3 assign probabilities to each token in a sequence.  \n",
        "\n",
        "In the playground, you can see the probabilities for the top-5 words predicted at each position by choosing the `Full Spectrum` option from the `Show probabilities` dropdown menu in the controls.  Try selecting that option and then generate a completion for the prompt\n",
        "\n",
        "> My favorite class in the Computer Science Department was taught by Professor\n",
        "\n",
        "If you mouse over the word after professor, you'll see something like this:\n",
        "```\n",
        "Joe = 8.21%\n",
        "John = 4.25%\n",
        "Nancy = 2.27%\n",
        "David = 2.09%\n",
        "Barbara = 2.05%\n",
        "Total: -2.50 logprob on 1 tokens\n",
        "(18.87% probability covered in top 5 logits\n",
        "```\n",
        "\n",
        "One critical observation about language models is that they often encode societal biases that appear in their data.  For instance, after the disovery that LM embeddings could be used to solve word analogy problems like \"**man** is to **woman** as **king** is to ___\" (the model predicts **queen**), researchers discovered that LMs had a surpisingly sexist answer to the analogy problem  \"**man** is to **woman** as **computer programmer** is to ___\" (the model predicts **homemaker**).  These kinds of biases are prevelant and pernicious.\n",
        "\n",
        "Let's examine the most probable names that GPT3 assigns to different completions and analyze their gender.  We'll see if it associates different genders with different academic disciplines.  (You can also see this for different careers like *nurse*, *plumber*, or *school teacher*).\n",
        "\n",
        "Please create dictionaries mapping GPT's predictions for the first names of professors in these departmemnts\n",
        "* Computer Science\n",
        "* Gender Studies\n",
        "* Physics\n",
        "* Linguisticss\n",
        "* Bioengineering\n",
        "Use the prompt:\n",
        "> My favorite class in the {deparment_name} Department was taught by Professor\n",
        "\n",
        "**Note: you can also add a stop sequence of `.` to get the model to complete only a single sentence.**\n",
        "\n"
      ],
      "metadata": {
        "id": "y0bIhdi24moc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Classify each name as male, female, partial word, or unknown\n",
        "computer_science_genders = {\n",
        "  \"Joe\" : \"male\",\n",
        "  \"John\" : \"male\",\n",
        "  \"Nancy\" : \"female\",\n",
        "  \"David\" : \"male\",\n",
        "  \"Barbara\" : \"female\",\n",
        "}\n",
        "\n",
        "gender_studies_genders = {\n",
        "  'Sarah': \"female\",\n",
        "  'Elizabeth': 'female',\n",
        "  'Jennifer': 'female',\n",
        "  'Laura': 'female',\n",
        "  'Mary': 'female',\n",
        "}\n",
        "\n",
        "physics_genders = {\n",
        "  \"John\" : \"male\",\n",
        "  \"David\" : \"male\",\n",
        "  \"Robert\" : \"male\",\n",
        "  \"Stephen\" : \"male\",\n",
        "  \"Michael\" : \"male\"\n",
        "}\n",
        "\n",
        "lingusitics_genders = {\n",
        "  \"David\" : \"male\",\n",
        "  \"John\" : \"male\",\n",
        "  \"Robert\" : \"male\",\n",
        "  \"Elizabeth\" : \"female\",\n",
        "  \"Paul\" : \"male\"\n",
        "}\n",
        "\n",
        "bioengineering_genders = {\n",
        "  \"David\" : \"male\",\n",
        "  \"John\" : \"male\",\n",
        "  \"Robert\" : \"male\",\n",
        "  \"Michael\" : \"male\",\n",
        "  \"Mark\" : \"male\"\n",
        "}"
      ],
      "metadata": {
        "id": "rj2Dt1BL4l-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(If you wanted to systematically explore the predictions of the model, you could use the API's logprobs argument to return the the log probabilities on the logprobs most likely tokens, as well the chosen tokens.)"
      ],
      "metadata": {
        "id": "DckHlrauFYdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few Shot Learning\n",
        "\n",
        "One of the remarkable properties of large language models is a consequence of the fact that they have been trained on so much language data.  They encode that training data as background information that lets them learn new tasks and to generalize patterns using only a few examples.  This is called \"Few shot learning\".\n",
        "\n",
        "Here is an example.  Imagine that we want to build a system that allows a student to say something they want to learn, and the system will recommend the subject for them to study.  Here are examples of inputs and outputs to our program:\n",
        "\n",
        "```\n",
        "how to program in Python - computer science\n",
        "factors leading up to WW2 - history\n",
        "branches of government - political science\n",
        "Shakespeare's plays - English\n",
        "cellular respiration - biology\n",
        "respiratory disease - medical\n",
        "how to sculpt - art\n",
        "```\n",
        "\n",
        "We can use these 7 examples (and probably fewer!) as a prompt to GPT-3, and it will perform few shot learning by figuring out what our pattern is, and being able to perform the task for new inputs.\n",
        "\n",
        "Try pasting those examples into the Playground, and then listing out a few subjects to see what is output.\n",
        "\n",
        "```\n",
        "cellular respiration\n",
        "respiratory disease\n",
        "how to play saxophone\n",
        "autonomic system\n",
        "how write a screenplay\n",
        "perform in a play\n",
        "stock market\n",
        "planetary orbits\n",
        "relativity\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "qV65mL6va3lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the dictionary below using the playground by replacing the TODOs with the model's predictions."
      ],
      "metadata": {
        "id": "CRMLTBoxe6V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_subject_classification_results = {\n",
        "  \"cellular respiration\" : \"biology\",\n",
        "  \"respiratory disease\" : \"medical\",\n",
        "  \"how to play saxophone\" : \"music\",\n",
        "  \"autonomic system\" : \"anatomy\",\n",
        "  \"how write a screenplay\" : \"creative writing\",\n",
        "  \"perform in a play\" : \"theatre\",\n",
        "  \"stock market\" : \"economics\",\n",
        "  \"planetary orbits\" : \"astronomy\",\n",
        "  \"relativity\" : \"physics\",\n",
        "}"
      ],
      "metadata": {
        "id": "cTaSq85Ka8WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the API\n",
        "\n",
        "Now let's take a look at how to call the OpenAI API from our code, so that we don't have to manually enter inputs into the Playground.  \n",
        "\n",
        "If you click on the \"View code\" button on the playground, you'll see a sample of code for whatever prompt you have.  For example, here's the code that we have for our few-shot learning that generates a subject to study for a topic that someone is interested in:\n",
        "\n",
        "```python\n",
        "import os\n",
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-002\",\n",
        "  prompt=\"how to program in Python - computer science\\nfactors leading up to WW2 - history\\nbranches of government - political science\\nShakespeare's plays - English\\ncellular respiration - biology\\nrespiratory disease - medical\\nhow to sculpt - art\",\n",
        "  temperature=0.7,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "```\n",
        "This is python code, so it'll be pretty easy for us to use this as a starting point and to modify it to create a function that we can call.\n",
        "\n",
        "\n",
        "First, you'll need install the OpenAPI via pip.  You can use pip and other Unix command in a colab notebook by prefixing them with an exclamation point.  (The `%%capture` command before that just surpresses the output of running the Unix command.  You can remove it if you want to see the progress of the command).\n"
      ],
      "metadata": {
        "id": "4VpROz_FfJZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "396iGnE4ra9g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, you will enter your secret key for the OpenAI API, then you can find your OpenAI API key [here](https://beta.openai.com/account/api-keys).  \n",
        "\n",
        "We will enter it as a password, so that the raw text of it doesn't get saved in your Python notebook and you accidentally make your notebook public.  That would be bad because then other people could use your key and have you pay for their usage."
      ],
      "metadata": {
        "id": "9jdqGfOyrmhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "import openai\n",
        "\n",
        "print('Enter OpenAI API key:')\n",
        "openai.api_key = getpass()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PIBX87qrlDd",
        "outputId": "6a9dbb6f-4fc7-4082-8c35-4549ad322dc0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write a function that takes a topic as input and then outputs a subject to study if you want to learn about that topic."
      ],
      "metadata": {
        "id": "yt7VVKVtvcCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import time\n",
        "\n",
        "def generate_subject_few_shot(topic):\n",
        "  few_shot_prompt = \"\"\"how to program in Python - computer science\n",
        "factors leading up to WW2 - history\n",
        "branches of government - political science\n",
        "Shakespeare's plays - English\n",
        "cellular respiration - biology\n",
        "respiratory disease - medical\n",
        "how to sculpt - art\n",
        "\"\"\"\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      model=\"text-davinci-002\",\n",
        "      prompt=few_shot_prompt + topic + \" - \", # We'll append our topic and a dash to the end of the few shot prompt.\n",
        "      temperature=0.7,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"\\n\"]\n",
        "  )\n",
        "  # I recommend putting a short wait after each call,\n",
        "  # since the rate limit for the platform is 60 requests/min.\n",
        "  # (This increases to 3000 requests/min after you've been using the platform for 2 days).\n",
        "  time.sleep(1)\n",
        "\n",
        "  # the response from OpenAI's API is a JSON object that contains\n",
        "  # the completion to your prompt plus some other information.  Here's how to access\n",
        "  # just the text of the completion.\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "topic = \"cellular respiration\"\n",
        "generate_subject_few_shot(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o9-oV9mnvmtD",
        "outputId": "c6376799-3323-4c93-a3fe-c770d5408531"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'science'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it!  That's an exampe of how to write a function call to the OpenAI API in order for it to output a subject for a topic.\n",
        "\n",
        "Here is some information about the different arguments that we to the `openai.Completion.create` call:\n",
        " * `model` – OpenAI offers four different sized versionf of the GPT-3 model: davinci, currie, babbage and ada.  Davinci has the largest number of parameters and is [the most expensive to run](https://openai.com/api/pricing/).  Ada has the fewest parameters, is the fastest to run and is the least expensive.\n",
        " * `prompt` - this is the prompt that the model will generate a completion for\n",
        " * `temperature` - controls how much of the probability distribution the model will use when it is generating each token. 1.0 means that it samples from the complete probability distrubiton, 0.7 means that it drops the bottom 30% of the least likely tokens when it is sampling. 0.0 means that it will perform deterministically and always output the single most probable token for each context.\n",
        " * `top_p` - is an alternative way of controling the sampling.\n",
        " * `frequency_penalty` and `presence_penalty` are two ways of reduing the model from repeating the same words in one output.  You can set these to be >0 if you're seeing a lot of repetition in your output.\n",
        " * `max_tokens` is the maximum length in tokens that will be output by calling the function.  A token is a subword unit.  There are roughly 2 or 3 tokens per word on average.\n",
        " * `stop` is a list of stop sequences.  The model will stop generating output once it generates one of these strings, even if it hasn't reached the max token length. By default this is set to a special token `<|endoftext|>`.\n",
        "\n",
        "You can read more about [the Completion API call in the documentation](https://beta.openai.com/docs/api-reference/completions)."
      ],
      "metadata": {
        "id": "Wmr06VEzxlnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero shot learning\n",
        "\n",
        "In addition to few shot learning, GPT-3 can sometimes also perform \"zero shot learning\" where instead of giving it several examples of what we want it to do, we can instead give it instructions of what we want it to do.\n",
        "\n",
        "For example, for our topic - subject task we could give GPT-3 the prompt\n",
        "\n",
        "> Given a topic, output the subject that a student should study if they want to know more about that topic.\n",
        "\n",
        "Then if we append\n",
        "> cellular respiration -\n",
        "\n",
        "GPT3 will output biology.\n",
        "\n",
        "Try to adapt the `generate_subject_few_shot` function to do a zero-shot version."
      ],
      "metadata": {
        "id": "h5iKKme91RMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_subject_zero_shot(topic):\n",
        "  # TODO - write this function\n",
        "  zero_shot_prompt = \"\"\"Given a topic, \\\n",
        "  output the subject that a student should study if they want to know more about that topic.\"\"\"\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      model=\"text-davinci-002\",\n",
        "      prompt=zero_shot_prompt + topic + \" - \", # We'll append our topic and a dash to the end of the few shot prompt.\n",
        "      temperature=0.7,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"\\n\"]\n",
        "  )\n",
        "  # I recommend putting a short wait after each call,\n",
        "  # since the rate limit for the platform is 60 requests/min.\n",
        "  # (This increases to 3000 requests/min after you've been using the platform for 2 days).\n",
        "  time.sleep(1)\n",
        "\n",
        "  # the response from OpenAI's API is a JSON object that contains\n",
        "  # the completion to your prompt plus some other information.  Here's how to access\n",
        "  # just the text of the completion.\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "topic = \"cellular respiration\"\n",
        "generate_subject_few_shot(topic)"
      ],
      "metadata": {
        "id": "aLve17Cl3d2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4d59190-1a87-4e38-8e80-08c54f24719d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'biology'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A very cool recent finding is that training proceedure for large language models can be changed to improve this instruction following behavior.  If large LMs are [trained to do multiple tasks through prompting](https://arxiv.org/abs/2110.08207), they better generalize to complete new tasks in a zero-shot fashion.  The current version of GPT3 (text-davinci-2) uses this kind of training.\n",
        "\n",
        "Try writing zero-shot prompts to do the following tasks:\n",
        "1. Summarize a Wikipedia article.\n",
        "2. Answer questions about an article.\n",
        "3. Re-write an article so that it's suitable for a young child who is just learning how to read (age 8 or so).\n",
        "4. Translate an article from Russian into English.\n",
        "\n",
        "You should experiment with a few prompts in the playground to find a good prompt that seems to work well."
      ],
      "metadata": {
        "id": "O3eB1xva5Nr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(article_text):\n",
        "  # TODO - write this function\n",
        "  summary = \"Summarize this Wikipedia article.\"\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt=summary + \"\\n'''\" + article_text + \"'''\\n\",\n",
        "      temperature=0.7,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"\\n\"]\n",
        "  )\n",
        "\n",
        "  time.sleep(1)\n",
        "\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "def answer_question(article_text, question):\n",
        "  # TODO - write this function\n",
        "  answer = \"Answer the question based on this Wikipedia article below.\"\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt= \"Question: \" + question \\\n",
        "      + \"\\n\" + answer + \"\\n'''\" + article_text + \"'''\\n\",\n",
        "      temperature=0.7,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"\\n\"]\n",
        "  )\n",
        "\n",
        "  time.sleep(1)\n",
        "\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "def simplify(article_text):\n",
        "  # TODO - write a function to re-write an article so that it's suitable for a young child.\n",
        "  simplified_article = \"Simplify the following article so that a 5-year-old can understand.\"\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt= simplified_article + \"\\n\\n'''\" + article_text + \"'''\",\n",
        "      temperature=0.7,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0\n",
        "  )\n",
        "\n",
        "  time.sleep(1)\n",
        "\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "def translate(article_text, source_language, target_language):\n",
        "    # TODO - write a function to translate an article from a source language to a target language.\n",
        "  translated_article = \"Translate the following article from \" + source_language + \" to \" + target_language\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt= translated_article + \"\\n\\n'''\" + article_text + \"'''\",\n",
        "      temperature=0.7,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0\n",
        "  )\n",
        "\n",
        "  time.sleep(1)\n",
        "\n",
        "  return response['choices'][0]['text'].strip()"
      ],
      "metadata": {
        "id": "g5AWEh526gIw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show your outputs in your prompts.  The colab notebook that you turn in should have these outputs for the TAs and professor to review."
      ],
      "metadata": {
        "id": "T9oCIWFW7-Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = \"\"\"\n",
        "The wandering albatross, snowy albatross, white-winged albatross or goonie(Diomedea exulans) \\\n",
        "is a large seabird from the family Diomedeidae, which has a circumpolar range in the Southern Ocean. \\\n",
        "It was the last species of albatross to be described, and was long considered the same species as the \\\n",
        "Tristan albatross and the Antipodean albatross. A few authors still consider them all subspecies of the same species. \\\n",
        "The SACC has a proposal on the table to split this species, and BirdLife International has already split it. \\\n",
        "Together with the Amsterdam albatross, it forms the wandering albatross species complex.\n",
        "\n",
        "The wandering albatross is one of the two largest members of the genus Diomedea (the great albatrosses), \\\n",
        "being similar in size to the southern royal albatross. It is one of the largest, best known, and most studied \\\n",
        "species of bird in the world. It has the greatest known wingspan of any living bird, and is also one of the most \\\n",
        "far-ranging birds. Some individual wandering albatrosses are known to circumnavigate the Southern Ocean three times, \\\n",
        "covering more than 120,000 km (75,000 mi), in one year.\n",
        "\"\"\"\n",
        "\n",
        "summarize(article_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "PiJrC5K-mm2u",
        "outputId": "c38eec68-09f5-4adf-ee19-74b9a7195625"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The wandering albatross (Diomedea exulans) is a large seabird found in the Southern Ocean. It is part of the Diomedeidae family and is the largest of the albatross species. It is known for its extensive wingspan, being the largest of any living bird, and its far-ranging habits, with some individuals being recorded to circumnavigate the Southern Ocean three times in a year. It is one of the most studied and well-known bird species in the world.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = \"\"\"\n",
        "The wandering albatross, snowy albatross, white-winged albatross or goonie(Diomedea exulans) \\\n",
        "is a large seabird from the family Diomedeidae, which has a circumpolar range in the Southern Ocean. \\\n",
        "It was the last species of albatross to be described, and was long considered the same species as the \\\n",
        "Tristan albatross and the Antipodean albatross. A few authors still consider them all subspecies of the same species. \\\n",
        "The SACC has a proposal on the table to split this species, and BirdLife International has already split it. \\\n",
        "Together with the Amsterdam albatross, it forms the wandering albatross species complex.\n",
        "\n",
        "The wandering albatross is one of the two largest members of the genus Diomedea (the great albatrosses), \\\n",
        "being similar in size to the southern royal albatross. It is one of the largest, best known, and most studied \\\n",
        "species of bird in the world. It has the greatest known wingspan of any living bird, and is also one of the most \\\n",
        "far-ranging birds. Some individual wandering albatrosses are known to circumnavigate the Southern Ocean three times, \\\n",
        "covering more than 120,000 km (75,000 mi), in one year.\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "    \"Which species are considered as the same species as the wandering albatross?\",\n",
        "    \"What genus does the wandering albatross belong to?\",\n",
        "    \"How does the wandering albatross look like?\",\n",
        "    \"What is the flying range of wandering albatross?\",\n",
        "    \"Who are the two largest members of the genus Diomedea?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "  answer = answer_question(article_text, question)\n",
        "  print(question)\n",
        "  print(answer)\n",
        "  print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GOa6xs8m1sH",
        "outputId": "afab51cc-4213-4090-b502-e051069c3ef6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which species are considered as the same species as the wandering albatross?\n",
            "The species considered to be the same as the wandering albatross are the Tristan albatross and the Antipodean albatross. Some authors still consider them all subspecies of the same species. The Amsterdam albatross also forms part of the wandering albatross species complex.\n",
            "---\n",
            "What genus does the wandering albatross belong to?\n",
            "Answer: The wandering albatross belongs to the genus Diomedea.\n",
            "---\n",
            "How does the wandering albatross look like?\n",
            "The wandering albatross is a large seabird with the greatest known wingspan of any living bird. It is white in colour with black flight feathers on the wings and a black tail. It has yellow-tipped bill, pink legs and feet, and a white head with a white eye patch.\n",
            "---\n",
            "What is the flying range of wandering albatross?\n",
            "The flying range of the wandering albatross is immense, and individual birds have been known to circumnavigate the Southern Ocean three times in one year, covering more than 120,000 km (75,000 mi).\n",
            "---\n",
            "Who are the two largest members of the genus Diomedea?\n",
            "The two largest members of the genus Diomedea are the wandering albatross and the southern royal albatross.\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = \"\"\"\n",
        "The wandering albatross, snowy albatross, white-winged albatross or goonie(Diomedea exulans) \\\n",
        "is a large seabird from the family Diomedeidae, which has a circumpolar range in the Southern Ocean. \\\n",
        "It was the last species of albatross to be described, and was long considered the same species as the \\\n",
        "Tristan albatross and the Antipodean albatross. A few authors still consider them all subspecies of the same species. \\\n",
        "The SACC has a proposal on the table to split this species, and BirdLife International has already split it. \\\n",
        "Together with the Amsterdam albatross, it forms the wandering albatross species complex.\n",
        "\n",
        "The wandering albatross is one of the two largest members of the genus Diomedea (the great albatrosses), \\\n",
        "being similar in size to the southern royal albatross. It is one of the largest, best known, and most studied \\\n",
        "species of bird in the world. It has the greatest known wingspan of any living bird, and is also one of the most \\\n",
        "far-ranging birds. Some individual wandering albatrosses are known to circumnavigate the Southern Ocean three times, \\\n",
        "covering more than 120,000 km (75,000 mi), in one year.\n",
        "\"\"\"\n",
        "\n",
        "simplify(article_text)"
      ],
      "metadata": {
        "id": "5d2SS-fT8klT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9f549c77-a3af-427a-da47-841ee7aad526"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The wandering albatross is a very big bird. It has the biggest wings of any bird. It lives in the Southern Ocean and some of them fly around the Southern Ocean three times in one year. That's like flying more than 120,000 km (75,000 mi).\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "russian_article = \"\"\"\n",
        "Странствующий альбатрос — одна из самых крупных летающих птиц — тело у неё достигают длины 120 см, масса взрослой самки — 7—9 кг, самца до 11 кг. Эти птицы считаются обладателями одного из самым больших среди современных птиц размаха крыльев — до 325 см. Рекорд принадлежит старому самцу, пойманному в 1965 году у берегов Австралии — размах его крыльев составлял 3 метра 63 сантиметра. Крылья у этой птицы длинные и узкие.\n",
        "\n",
        "У взрослых особей оперение полностью белое, за исключением тонких чёрных каёмок на задней части крыльев. У этих птиц мощный клюв, а лапы имеют бледный розовый оттенок. Глаза, как правило, тёмно-коричневого цвета. Молодняк существенно отличается от взрослых по своему внешнему виду. У него бурое оперение, которое лишь со временем выцветает и превращается в белое. Последние остатки бурой окраски встречаются, как правило, в качестве полоски на груди.\n",
        "\"\"\"\n",
        "\n",
        "source_language = \"Russian\"\n",
        "target_language = \"English\"\n",
        "translate(russian_article, source_language, target_language)"
      ],
      "metadata": {
        "id": "w8f1cGZN8nX4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3ec7b925-dcae-44f9-d622-b42d669eaf13"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The wandering albatross is one of the largest flying birds - its body reaches a length of 120 cm, the weight of an adult female is 7-9 kg, and the male is up to 11 kg. These birds are considered to have one of the largest wingspans among modern birds - up to 325 cm. The record belongs to an old male caught in 1965 near the coast of Australia - the wingspan of his wings was 3 meters 63 centimeters. The wings of this bird are long and narrow.\\n\\nAdult plumage is completely white, except for thin black edging on the back of the wings. These birds have a powerful beak, and their paws have a pale pink tint. The eyes are usually dark brown. The chicks differ significantly from adults in appearance. It has a brown plumage that gradually fades and turns white. The last remnants of brown color are usually in the form of stripes on the chest.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO - Pick your own task\n",
        "\n",
        "For this section you should pick some task that you'd like to have GPT3 do.  Add a description and code to your notebook here.  You should:\n",
        "1. Write a short description of what task you tried, why you were interested in it.\n",
        "2. Give some code so that we can reproduce what you did via an Open API call.  You should include output of your code in the Python Notebook that you turned in.\n",
        "3. Write a short qualitative analysis of whether or not GPT3 did the task well."
      ],
      "metadata": {
        "id": "mVe3k3sl9p6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO - your task description\n",
        "\n",
        "**Given the signalment and symptoms of a canine patient, ask GPT3 to generate a list of differential diagnosis.**\n",
        "\n",
        "Why interested? I am a Veterinarian, Doctor of Veterinary medicine, myself. I am curious how GPT3 would perform as a virtual veterinarian when it comes to some cases that a general practitioner would see routinely at the clinics."
      ],
      "metadata": {
        "id": "Y7uWoojg-YY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO your code\n",
        "def diagnose(signalment):\n",
        "    # TODO - write a function to translate an article from a source language to a target language.\n",
        "  ddx_prompt = \"\"\"\n",
        "  Give a list of differential diagnosis for this canine patient based on the signalment and symptoms provided below.\n",
        "  \"\"\"\n",
        "\n",
        "  response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt= ddx_prompt + \"\\n\\n'''\" + signalment + \"'''\",\n",
        "      temperature=0.7,\n",
        "      max_tokens=256,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0\n",
        "  )\n",
        "\n",
        "  time.sleep(1)\n",
        "\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "signalments = [\n",
        "    \"Coco is a 12-year-old spayed female poodle who was presented for chronic dry skin with scaling, \\\n",
        "    weight gain, inactivity, depressed mentation and cold intolerance. Her CBC shows normocytic, normochromic, non-regenerative anemia. \\\n",
        "    Her chemistry panel reveals hypercholesterolemia, elevated ALP and ALT. Total T4 test is lower than normal.\",\n",
        "    \"Grace is a 3-year-old intact male Great Dane, presented for polyruria, inappetence, lethargy, chronic vomiting and diarrhea, weight loss. \\\n",
        "    CBC shows mild anemia, neutrophilia, lymphocytosis and mild eusinophilia. Chemistry shows azotemia, electrolyte imbalance (hyperkalemia, hyponatremia, \\\n",
        "    hypochloremia) and acidosis.\",\n",
        "    \"Pup is a 10-year-old spayed female American Cocker Spaniel, presented for squinting, nictitating membrane protrusion, red eye and mydriasis. \\\n",
        "    She has been bumping into things more often recently, and the owner worried it was due to her reduced vision. On her ocular examination, \\\n",
        "    both eyes had an IOP over 30mmHg, and Gonioscoipic exam reveals reduced iridocorneal angle in both eyes. \"\n",
        "               ]\n",
        "for sig in signalments:\n",
        "  ddx = diagnose(sig)\n",
        "  print(sig)\n",
        "  print(ddx)\n",
        "  print('---')"
      ],
      "metadata": {
        "id": "FgwbDBsS-a2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354217b7-00cc-499d-96e1-fb1766a1a746"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coco is a 12-year-old spayed female poodle who was presented for chronic dry skin with scaling,     weight gain, inactivity, depressed mentation and cold intolerance. Her CBC shows normocytic, normochromic, non-regenerative anemia.     Her chemistry panel reveals hypercholesterolemia, elevated ALP and ALT. Total T4 test is lower than normal.\n",
            "Differential Diagnoses: \n",
            "1. Hypothyroidism\n",
            "2. Hypoadrenocorticism\n",
            "3. Diabetes mellitus\n",
            "4. Renal disease\n",
            "5. Liver disease\n",
            "6. Hyperlipidemia\n",
            "7. Cancer\n",
            "8. Allergy\n",
            "9. Infectious disease\n",
            "10. Immune-mediated disorder\n",
            "---\n",
            "Grace is a 3-year-old intact male Great Dane, presented for polyruria, inappetence, lethargy, chronic vomiting and diarrhea, weight loss.     CBC shows mild anemia, neutrophilia, lymphocytosis and mild eusinophilia. Chemistry shows azotemia, electrolyte imbalance (hyperkalemia, hyponatremia,     hypochloremia) and acidosis.\n",
            "Differential diagnoses for Grace:\n",
            "1. Gastrointestinal disease (e.g. inflammatory bowel disease, exocrine pancreatic insufficiency, parasitic infestation)\n",
            "2. Urinary tract infection\n",
            "3. Renal disease (e.g. glomerulonephritis, pyelonephritis, chronic kidney disease)\n",
            "4. Pancreatitis\n",
            "5. Diabetes mellitus\n",
            "6. Cushing’s disease\n",
            "7. Primary hyperaldosteronism\n",
            "8. Hypoadrenocorticism\n",
            "9. Liver disease (e.g. hepatic lipidosis, cholangiohepatitis)\n",
            "10. Immune-mediated hemolytic anemia\n",
            "---\n",
            "Pup is a 10-year-old spayed female American Cocker Spaniel, presented for squinting, nictitating membrane protrusion, red eye and mydriasis.     She has been bumping into things more often recently, and the owner worried it was due to her reduced vision. On her ocular examination,     both eyes had an IOP over 30mmHg, and Gonioscoipic exam reveals reduced iridocorneal angle in both eyes. \n",
            "Differential Diagnoses: \n",
            "1. Glaucoma \n",
            "2. Uveitis \n",
            "3. Cataract \n",
            "4. Tumor \n",
            "5. Lens Luxation \n",
            "6. Optic Nerve Hypoplasia \n",
            "7. Corneal Dystrophy \n",
            "8. Retinal Degeneration \n",
            "9. Trauma \n",
            "10. Thyroid Eye Disease\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO - write a short paragraph giving your qualitative analysis of how well GPT3 did for your task.\n",
        "\n",
        "The correct diagnoses for the above cases are:\n",
        "\n",
        "1. Hypothyroidism (Correct by GPT)\n",
        "\n",
        "2. Hypoadrenocorticism/Addison's Disease (Wrong by GPT)\n",
        "\n",
        "3. Glaucoma (Correct by GPT)\n",
        "\n",
        "The first two endocrine caes are relatively challenging. With only the signalment, limited symptoms and diagnostic results, GPT3 got one of these two wrong, which is not disappointing. Overall, GPT3's performace is decent as a virtual veterinarian."
      ],
      "metadata": {
        "id": "v9CjM8hM-cc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning\n",
        "\n",
        "In addition to zero-shot and few-shot learning, another way of getting large language models to do your tasks is via a process called \"fine tuning\".  In fine-tuning the model updates its parameters so that it performs well on many training examples.  The training examples are in the form of input prompts paired with gold standard completions.\n",
        "\n",
        "Large language models are pre-trained to perform well on general tasks like text completion but not on the specific task that you might be interested in.  The models can be fine tuned to perform you task, starting with the model parameters that are good for the general setting, and then updating them to be good for your task.\n",
        "\n",
        "We'll walk through how to fine-tune GPT3 for a task.\n"
      ],
      "metadata": {
        "id": "7x8z9JJnAQs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this example, we will show you how to fine tune GPT3 to write biographies. From data in the info boxes in Wikipedia pages.  For instance, given this input\n",
        "\n",
        "```\n",
        "notable_type: scientist\n",
        "name: Zulima Aban\n",
        "gender: female\n",
        "birth_date: 05 December 1905\n",
        "birth_place: Valencia, Spain\n",
        "death_date: 09 August 1983\n",
        "death_place: Detroit, Michigan, U.S.\n",
        "death_cause: Pulmonary embolism\n",
        "occupation: Astronomer\n",
        "fields: Astrophysics, Computer Science, Computer Graphics, Interface Design, Image Synthesis\n",
        "known_for: The Search for Planet Nine\n",
        "hometown: Detroit, Michigan, U.S.\n",
        "nationality: Venezuelan\n",
        "citizenship: Spanish, American\n",
        "alma_mater: University of Valencia (B.Sc.), University of Madrid (Ph.D.)\n",
        "thesis_title: The Formation of Planets by the Accretion of Small Particles\n",
        "thesis_year: 1956\n",
        "doctoral_advisor: Angela Carter\n",
        "awards: Spanish Academy of Science, Spanish Academy of Engineering, German Aerospace Prize, IEEE Medal of Honor, IEEE John von Neumann Medal, IEEE Jack S. Kilby Signal Processing Medal, United Nations Space Pioneer Award, Wolf Prize in Physics\n",
        "institutions: Oberlin College, University of Valencia, Instituto de Astrofísica de Andalucía (CSIC), University of Southern California, Space Telescope Science Institute (STScI)\n",
        "notable_students: Ryan Walls\n",
        "influences: Immanuel Kant, Albert Einstein, Kurt Gödel, Gottfried Leibniz, Richard Feynman, Werner Heisenberg, William Kingdon Clifford, Sir Arthur Eddington\n",
        "influenced: Joseph Weinberg\n",
        "mother: Ana Aban\n",
        "father: Joaquín Aban\n",
        "partner: Georgina Abbott\n",
        "children: Robert, Peter, Sarah\n",
        "```\n",
        "\n",
        "The fine-tuned model will generate this output:\n",
        "\n",
        "> Zulima Aban was a Venezuelan astronomer, who was born on 05 December 1905 in Valencia, Spain to Ana Aban and Joaquín Aban. Her career involved the fields of Astrophysics, Computer Science, Computer Graphics, Interface Design, Image Synthesis. Aban was known for The Search for Planet Nine. Aban went to University of Valencia (B.Sc.), University of Madrid (Ph.D.). Aban's thesis title was The Formation of Planets by the Accretion of Small Particles in 1956. Her doctoral advisor was Angela Carter. Aban received Spanish Academy of Science, Spanish Academy of Engineering, German Aerospace Prize, IEEE Medal of Honor, IEEE John von Neumann Medal, IEEE Jack S. Kilby Signal Processing Medal, United Nations Space Pioneer Award, Wolf Prize in Physics. Aban went to Oberlin College, University of Valencia, Instituto de Astrofísica de Andalucía (CSIC), University of Southern California, Space Telescope Science Institute (STScI). Her notable students were Ryan Walls. Aban was influenced by Immanuel Kant, Albert Einstein, Kurt Gödel, Gottfried Leibniz, Richard Feynman, Werner Heisenberg, William Kingdon Clifford, Sir Arthur Eddington and she infuenced Joseph Weinberg. Aban was married to Georgina Abbott and together had three children, Robert, Peter, Sarah. Aban died on 09 August 1983 in Detroit, Michigan, U.S due to Pulmonary embolism.\n",
        "\n",
        "The dataset that we will use was created for the paper [SynthBio: A Case Study in Human-AI Collaborative Curation of Text Datasets](https://www.cis.upenn.edu/~ccb/publications/synthbio.pdf) by Ann Yuan, Daphne Ippolito, Vitaly Nikolaev, Chris Callison-Burch, Andy Coenen, and Sebastian Gehrmann. It was published in NeurIPS 2021.  The goal of the paper was to create a curated dataset for training large language models on synthetic data with the goal of avoiding the gender and geographic bias that is naturally present in Wikipedia due to cultural and historic reasons.\n"
      ],
      "metadata": {
        "id": "GDez1YvZHFaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ],
      "metadata": {
        "id": "j1WbRlYDIadg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_train.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mrmOrl6Ad0E",
        "outputId": "8c078508-ce09-4d17-ff33-9c38e9b31738"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-01 04:53:46--  https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5807118 (5.5M) [text/plain]\n",
            "Saving to: ‘SynthBio_train.json.1’\n",
            "\n",
            "SynthBio_train.json 100%[===================>]   5.54M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-08-01 04:53:46 (70.6 MB/s) - ‘SynthBio_train.json.1’ saved [5807118/5807118]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a file called 'SynthBio.json' which is a list of json objects.\n",
        "# Pretty the first 5 json examples, nicely formatted.\n",
        "\n",
        "import json\n",
        "import random\n",
        "\n",
        "def load_wiki_bio_data(filename='SynthBio_train.json', num_bios=100, randomized=True):\n",
        "  with open(filename) as f:\n",
        "    synth_bio_data = json.load(f)\n",
        "  random.shuffle(synth_bio_data)\n",
        "  bios = []\n",
        "  for data in synth_bio_data:\n",
        "    notable_type = data['notable_type']\n",
        "    attributes = \"notable_type: {notable_type} | {other_attributes}\".format(\n",
        "        notable_type = notable_type,\n",
        "        other_attributes = data['serialized_attrs']\n",
        "    )\n",
        "    biography = data['biographies'][0]\n",
        "    bios.append((attributes.replace(\" | \", \"\\n\"), biography))\n",
        "  return bios[:min(num_bios, len(bios))]\n",
        "\n",
        "wiki_bios = load_wiki_bio_data()\n"
      ],
      "metadata": {
        "id": "RFXcmRh-Chll"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes, bio = wiki_bios[0]\n",
        "print(attributes)\n",
        "print('---')\n",
        "bio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "hOeMh6leD0gi",
        "outputId": "ad080921-03f7-4ac6-d93f-715f986c1742"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "notable_type: artist\n",
            "name: Vladimir Vladimirovich\n",
            "gender: male\n",
            "nationality: Russian\n",
            "birth_date: 17 August 1919\n",
            "birth_place: Moscow, Russia\n",
            "death_date: 16 September 2011\n",
            "death_place: Novosibirsk, Russia\n",
            "death_cause: old age\n",
            "resting_place: Tundra in Novosibirsk\n",
            "known_for: being a renown landscape artist, his works depicting mostly tundras in the Novosibirsk area\n",
            "notable_works: \"In Spring\", \"Meadow\"\n",
            "movement: landscape surrealist\n",
            "alma_mater: Novosibirsk Art Institute\n",
            "elected: Member of the Union of Russian Artists, member of the international Association of Artists, People's Artist of the Russian Federation, People's Artist of the Novosibirsk region\n",
            "children: Nikanor Artemievich\n",
            "---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Vladimir Vladimirovich Makovsky was born on August 17, 1919 in Moscow, Russia. His father was Nikanor Artemievich Makovsky, a painter and art teacher. Makovsky's childhood was quiet and comfortable, and his parents encouraged his love for art. He studied at the Moscow Art School from 1934 until 1937. Makovsky was a member of the Union of Russian Artists, and was elected to the international Association of Artists. He was also a member of the Russian Academy of Arts. He died in Novosibirsk on September 16, 2011, at the age of 92.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Format Data for Fine-Tuning\n",
        "\n",
        "Below, I show how to format data to fine-tune OpenAI.  The OpenAI API documentation has a [guide to fine-tuning models](https://beta.openai.com/docs/guides/fine-tuning) that you should read.   The basic format of fine-tuning data is a JSONL file (one JSON object per line) with two key-value pairs: `prompt:` and `completion:`.\n",
        "\n",
        "```\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "...\n",
        "```\n",
        "\n",
        "In the code below, I'll extract a prompt that contains the `attributes` variable from the intent dtermination data, and I'll have the completion be the `biography` variable."
      ],
      "metadata": {
        "id": "qDZYB6CW2m7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def create_wikibio_finetuning_data(wikibios, fine_tuning_filename):\n",
        "  fine_tuning_data = []\n",
        "\n",
        "  for attributes, bio in wiki_bios:\n",
        "    prompt = \"{attributes}\\n---\\n\".format(attributes=attributes)\n",
        "    completion = \"Biography: {bio}\\n###\".format(bio=bio)\n",
        "    data = {}\n",
        "    data['prompt'] = prompt\n",
        "    data['completion'] = completion\n",
        "    fine_tuning_data.append(data)\n",
        "\n",
        "  random.shuffle(fine_tuning_data)\n",
        "  with open(fine_tuning_filename, 'w') as out:\n",
        "    for data in fine_tuning_data:\n",
        "        out.write(json.dumps(data))\n",
        "        out.write('\\n')\n",
        "\n",
        "\n",
        "fine_tuning_filename='wikibio_finetuning_data.jsonl'\n",
        "create_wikibio_finetuning_data(wiki_bios, fine_tuning_filename)"
      ],
      "metadata": {
        "id": "2UKlNc01b4LR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll perform fine-tuning with this data using OpenAI."
      ],
      "metadata": {
        "id": "wEqja42Yc5O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade openai\n",
        "!pip install jsonlines\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "og19yX-Mc4-i"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you've got access to the OpenAI API, you can find your OpenAI API key [here](https://beta.openai.com/account/api-keys)."
      ],
      "metadata": {
        "id": "fE8RjE6SdGGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from getpass import getpass\n",
        "print('Enter OpenAI API key:')\n",
        "openai.api_key = getpass()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ],
      "metadata": {
        "id": "g2uAKwEzdGrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c58f45f-2422-4acd-8fa7-107aa3687739"
      },
      "execution_count": 65,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head '{fine_tuning_filename}'"
      ],
      "metadata": {
        "id": "P9SVG2fudLK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4405c87e-5139-49af-ea5c-5016896922b5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"prompt\": \"notable_type: athlete\\nname: Leonardo da Silva Santos\\ngender: non-binary\\nnationality: Brazilian\\nbirth_date: 29 November 1987\\nbirth_place: Rio de Janeiro, Brazil\\nsport: judo\\nhometown: Sao Paulo, Brazil\\ncitizenship: Brazilian\\neducation: University of Bras\\u00edlia (BSc), Griffith University (PhD)\\ncollegeteam: Griffith University\\nevent: judo\\nyears_active: 2008\\nheight: 5ft 7in\\nweight: 160lb\\ncoach: Paulo Wanderley\\nnational_team: Brazil\\nworlds: 2012 Summer Olympics - ninth\\nolympics: 2012 Summer Olympics - ninth\\nmother: Aloisio da Silva Santos\\npartner: Gabriel Aguiar\\n---\\n\", \"completion\": \"Biography: Leonardo da Silva Santos 29 November 1987 was a Brazilian judo athlete who competed at the 2012 Summer Olympics. Santos was born to Aloisio da Silva in Rio de Janeiro, Brazil of home town in Sao Paulo, Brazil. They attended the University of Bras\\u00edlia (BSc) and Griffith University (PhD).Santos was the ninth competitor to be eliminated from the 2012 Summer Olympics and trained by coach Paulo Wanderley with the height of 5ft 7in and weight of 160lb .Santos is married to Gabriel Aguiar.\\n###\"}\n",
            "{\"prompt\": \"notable_type: mountaineer\\nname: Satoru Tatsuya\\ngender: male\\nnationality: Japanese\\nbirth_date: 02 March 1970\\nbirth_place: Tokyo\\nstart_age: 16\\nnotable_ascents: Fuji Mountain, Mont Blanc, Kilimanjaro, Aconcagua, McKinley, Elbrus\\nfinal_ascent: Everest\\npartnerships: Yasunari Ina\\nmother: Emi Oshima\\nfather: Yosuke Oshima\\npartner: Nozomi Oshima\\nchildren: Yuki Nobu Oshima\\n---\\n\", \"completion\": \"Biography: Satoru Tatsuya born 2 March, 1970 is a Japanese in Tokyo. They were the son of Emi Oshima and Yosuke Oshima and were married Nozomi Oshima and had one children Yuki Nobu Oshima. Satoru Tatsuyu successfull in Fuji Mountain, Mont Blanc, Kilimanjaro, Aconcagua, McKinley and also made a solo ascent of the everest.\\n###\"}\n",
            "{\"prompt\": \"notable_type: mountaineer\\nname: Marisol Guate\\ngender: female\\nnationality: Guatemalan\\nbirth_date: 28 April 1964\\nbirth_place: Guatemala City, Guatemala\\ndeath_date: January 11, 2019\\ndeath_place: Lukla, Nepal\\ndeath_cause: slipped on a rock at 5 AM on Cho La Pass\\nresting_place: Guatemalensis Cemetery in Guatemala City\\nstart_age: 5\\nnotable_ascents: Mt. Kilimanjaro, Mt. Toubkal, Mt. Elbrus, Mt. Aconcagua\\nfinal_ascent: Mt. Everest.\\npartnerships: Juana Rivas, Anita Garcilazo, Irene Rodriguez, Ana Fernandez\\nmother: Margarita Guate\\nfather: Alfonso Guate\\npartner: Juana Rivas\\nchildren: Alfonso Guate III and Margarita Fernandez Guate\\n---\\n\", \"completion\": \"Biography: Marisol Guate (born 28 April 1964) was a Guatemalan mountaineer born to Margarita Guate and Alfonso Guate. Her notable ascents were Mt. Kilimanjaro, Mt. Toubkal, Mt. Elbrus, Mt. Aconcagua and final ascent was Mt. Everest. Marisol had partnerships with Juana Rivas, Anita Garcilazo, Irene Rodriguez, Ana Fernandez. Marisol was married to Juana Rivas and together had two children, Alfonso Guate III and Margarita Fernandez Guate. Marisol died by slipped on a rock at 5 AM on Cho La Pass on January 11, 2019 in Lukla, Nepal. And her remains were done in Guatemalensis Cemetery in Guatemala City.\\n###\"}\n",
            "{\"prompt\": \"notable_type: spy\\nname: Vasilika Hoxhaj\\ngender: female\\nnationality: Albanian\\nbirth_date: 31 May 1970\\nbirth_place: Prishtina, Yugoslavia\\nalma_mater: University of Prishtina, Serbia\\noccupation: librarian\\ncodename: The Librarian\\nallegiance: CIA, Mossad\\nmother: Maria Hoxhaj\\n---\\n\", \"completion\": \"Biography: Vasilika Hoxhaj was a librarian at the University of Prishtina, Serbia in Kosovo. Hoxhaj was born on May 31, 1970 in Prishtina, Yugoslavia to mother Maria Hoxhaj. Hoxhaj began working as a librarian at the University of Prishtina. Hoxhaj was recruited by the CIA and Mossad. Her codename was The Librarian.\\n###\"}\n",
            "{\"prompt\": \"notable_type: athlete\\nname: Kyrgyzbek Sukhumbayev\\ngender: male\\nnationality: Kyrgyzstani\\nbirth_date: 31 August 1915\\nbirth_place: Suzak District, Kyrgyzstan\\ndeath_date: 13 September 2005\\ndeath_cause: pneumonia\\nresting_place: Boroven Cemetery, Bishkek, Kyrgyzstan\\nsport: wrestling\\ncountry: Kyrgyzstan\\nhometown: Suzak District\\ncitizenship: Kyrgyzstan\\neducation: University of Bishkek (1943)\\nevent: sports wrestling\\nposition: featherweight\\nyears_active: 1936-1969\\nretired: 1969\\nheight: 5ft 9in\\nweight: 152lb\\ncoach: Nikolay Georgiyev\\nolympics: 1936 Summer Olympics - Bantamweight - 4th\\nmother: Zhanna Abdullina\\nfather: Khaptan Sukhobaev\\npartner: Maalay Kasymova\\nchildren: Asel, Khadizha, Gulzay, Shamiram\\n---\\n\", \"completion\": \"Biography: Kyrgyzbekovich Sukhumbayev was born on August 31, 1915 in the Suzak District of the Kyrgyzstan. He was well known for being a skilled wrestler, who competed in the featherweight division. He competed in the 1936 Summer Olympics in Berlin, Germany, where he finished fourth in the bantamweight category. Sukhumbayev went to University of Bishkek (1943) and his coach was Nikolay Georgiyev. Sukhumbayev's height was 5ft 9in and weight was 152lb. Sukhumbayev was born to Zhanna Abdullina and Khaptan Sukhobaev and he was survived with partner Maalay Kasymovaand four children, Asel, Khadizha, Gulzay, Shamiram. Sukhumbayev was died on 13 September 2005 of pneumonia and was laid to rest in Boroven Cemetery, Bishkek, Kyrgyzstan.\\n###\"}\n",
            "{\"prompt\": \"notable_type: writer\\nname: Solomon Mwenje\\ngender: male\\nnationality: Zimbabwean\\nbirth_date: November 07, 2006\\ndeath_place: Salisbury, Southern Rhodesia\\ndeath_cause: cancer\\nresting_place: Harare, Zimbabwe\\nalma_mater: University of Cape Town\\neducation: Bachelor of Arts - classical civilization, Bachelor of Arts - English literature, Master of Arts - English literature\\noccupation: novelist, short story writer, critic\\nnotable_works: The Lion, The First Edition, The Last Confessions\\nlanguage: English\\ngenre: fiction\\nawards: Heinemann Prize in 1970, Neustadt International Prize in Literature in 1976\\nmother: Dora Mwenje\\nfather: Rev. Abraham Mwenje\\npartner: Isolde Phillips\\nchildren: one son and one daughter\\n---\\n\", \"completion\": \"Biography: Solomon Mwenje was a Zimbabwean novelist, short story writer, and critic. He was born on November 7 1944, to Dora and Rev. Abraham Mwenje. Abraham Mwenje. He attended the University of Cape Town, where he earned a Bachelor of Arts - classical civilization, Bachelor of Arts - English literature, Master of Arts - English literature. Mwenje notable works include The Lion, The First Edition, The Last Confessions and his genre was fiction. Mwenje knows english language nad received Heinemann Prize in 1970, Neustadt International Prize in Literature in 1976. Mwenje was married to Isolde Phillips and had one son and one daughter. Mwenje was died of cancer ans was cremated in Harare, Zimbabwe.\\n###\"}\n",
            "{\"prompt\": \"notable_type: scientist\\nname: Albert H. Spencerworth\\ngender: male\\nbirth_date: 26 April 1874\\nbirth_place: Liverpool, UK\\ndeath_date: 22 October 1945\\ndeath_place: London, UK\\ndeath_cause: car accident\\nresting_place: Highgate Cemetery\\noccupation: astrophysicist\\nfields: science and mathematics\\nknown_for: Spencerworth's theory on the formation of galaxies\\nhometown: London, UK\\nnationality: British\\ncitizenship: British\\nalma_mater: Trinity College (BA), Cambridge University (PhD 1908)\\nthesis_title: The theory of gravitational lensing\\nthesis_year: 1908\\ndoctoral_advisor: Henry Pellatt\\ninstitutions: Cambridge University, Queen's University\\nnotable_students: Jaimie Guzman\\ninfluences: Albert A. Michelson\\ninfluenced: Jaimie Guzman\\nmother: Mary Spencerworth\\nfather: Albert Spencerworth\\npartner: Margaret Spencerworth\\nchildren: Alexander Spencerworth, Eleanor Spencerworth, Edward Spencerworth\\n---\\n\", \"completion\": \"Biography: Albert Henry Spencerworth (26 April 1874 - 22 October 1945) was a British astrophysicist and scientist and mathematician . He was born in Liverpool, UK, to Albert Spencerworth and Mary Spencerworth. He attended Trinity College Trinity College (BA), Cambridge University (PhD 1908) and completed his thesis \\\"The theory of gravitational lensing\\\" in 1908. Henry doctoral advisor was Henry Pellatt and he went to Cambridge University, Queen's University. Henry was known for Spencerworth's theory on the formation of galaxies and his notable students were Jaimie Guzman. He died in London, UK in a car accident and is buried at Highgate Cemetery. Henry influences were Albert A. Michelson and also influenced Jaimie Guzman. Henry was survived by his partner Margaret, his three children Alexander, Eleanor, and Edward.\\n###\"}\n",
            "{\"prompt\": \"notable_type: writer\\nname: Cindy Caceres\\ngender: female\\nnationality: Costa Rican\\nbirth_date: 30 July 1912\\nbirth_place: Desamparados, Costa Rica\\ndeath_date: November 11, 1983\\ndeath_place: Puntarenas, Costa Rica\\ndeath_cause: heart attack\\nresting_place: Puriscal, Costa Rica\\nalma_mater: University of Costa Rica\\neducation: BA in literature\\nlanguage: Spanish\\ngenre: romantic fiction\\nawards: Costa Rican fiction\\nmother: Ester Caceres\\nfather: Alberto Caceres\\npartner: Roberto Arango\\nchildren: none\\n---\\n\", \"completion\": \"Biography: Cindy Caceres was born on July 30, 1912 in Desamparados, Costa Rica. Her parents were Alberto Caceres and Ester Caceres. She attended the University of Costa Rica where she earned a BA in literature. She published several poems and prose works in various literary magazines. Cindy knows the Spanish Language. She was given an award in Costa Rican fiction. Caceres died on November 11, 1983 in Puntarenas, Costa Rica. She is buried in Puriscal, Costa Rica.\\n###\"}\n",
            "{\"prompt\": \"notable_type: artist\\nname: Steve Svetlik\\ngender: male\\nnationality: Slovakian\\nbirth_date: 11 October 1863\\nbirth_place: Kladzany, Czechoslovakia\\ndeath_date: September 28, 1928\\ndeath_place: Stare Mestice, Czechoslovakia\\ndeath_cause: car crash\\nresting_place: Stare Mestice Cemetery\\nknown_for: realism, fantasy\\nmovement: impressionism\\nalma_mater: Academia, Art Institute of Prague\\nawards: Cross of Merit for Science and Art\\nelected: none\\nmother: Agnes Svetlicek\\nfather: Jan Svetlik\\npartner: Sophie Svetlik\\nchildren: none\\n---\\n\", \"completion\": \"Biography: Steve Svetlik was born in Kladzany, Czechoslovakia on October 11, 1863. He was educated at the Art Institute of Prague. He was awarded the Cross of Merit for Science and Art. Steve is best known for realism, fantasy and his movements were impressionism. Steve was born to Jan Svetlik, Agnes Svetlicek and married to Sophie Svetlik. Steve Svetlik died on September 28, 1928 in a car crash near Stare Mestice, Czechoslovakia. He was buried in Stare Mestice Cemetery.\\n###\"}\n",
            "{\"prompt\": \"notable_type: mountaineer\\nname: Isabella Norrstr\\u00f6m\\ngender: female\\nnationality: Swedish\\nbirth_date: 14 April 1889\\nbirth_place: the port city of Gothenburg\\ndeath_date: 30 November 1928\\ndeath_place: Kangchenjunga\\ndeath_cause: ice axe fell from her hands due to exhaustion and her body disappeared into a deep crevasse\\nresting_place: north face of Kangchenjunga\\nstart_age: 12\\nnotable_ascents: Matterhorn, the Dom, La Luz\\nfinal_ascent: Kangchenjunga\\npartnerships: Tom K\\u00f6rling\\nmother: Kerstin Norrstr\\u00f6m\\nfather: Henning Norrstr\\u00f6m\\npartner: Tom K\\u00f6rling\\nchildren: two sons\\n---\\n\", \"completion\": \"Biography: Isabella Norrstr\\u00f6m (born 14 April 1889) was a Swedish mountaineer. She was born in the port city of Gothenburg, Sweden to Kerstin and Henning Norrstr\\u00f6m. She started climbing when she was 12 years old, and her notable works include Matterhorn, the Dom, La Luz and Kangchenjunga. Isabella had partnerships with Tom K\\u00f6rling. Isabella was married to Tom K\\u00f6rling and together had two sons. Isabella died on 30 November 1928 in Kangchenjunga of ice axe fell from her hands due to exhaustion and her body disappeared into a deep crevasse and was laid to rest in north face of Kangchenjunga.\\n###\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the fine-tuning API"
      ],
      "metadata": {
        "id": "XZDGRBY5ixfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll make the fine tuning API call via the command line.  Here the -m argument gives the model.  There are 4 sizes of GPT3 models.  They go in alphabetical order from smallest to largest.\n",
        "* Ada\n",
        "* Baddage\n",
        "* Currie\n",
        "* Davinci\n",
        "\n",
        "The models as the model sizes increase, so does their quality and their cost.  Davinci is the highest quality and highest cost model.  I recommend starting by fine-tuning smaller models to debug your code first so that you don't rack up costs.  Once you're sure that your code is working as expected then you can fine-tune a davinci model.\n"
      ],
      "metadata": {
        "id": "YzqdtSXzdXD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t '{fine_tuning_filename}' -m curie\n",
        "#!openai api fine_tunes.create -t '{fine_tuning_filename}' -m davinci"
      ],
      "metadata": {
        "id": "ZJ9-kAe1dWRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eeb3cc1-c6c2-41cb-9305-984edf9ff92b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/130k [00:00<?, ?it/s]\rUpload progress: 100% 130k/130k [00:00<00:00, 89.4Mit/s]\n",
            "Uploaded file from wikibio_finetuning_data.jsonl: file-ymQeYDSa0DR43Qj2JCQIMaWK\n",
            "Created fine-tune: ft-QeLEi4X7tcDP4tz3pkAajWTA\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-08-01 02:32:03] Created fine-tune: ft-QeLEi4X7tcDP4tz3pkAajWTA\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-QeLEi4X7tcDP4tz3pkAajWTA\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-QeLEi4X7tcDP4tz3pkAajWTA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVLuCR04_JEM",
        "outputId": "5c68c917-1b01-441d-f56c-5fa9221bb6b1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-08-01 02:32:03] Created fine-tune: ft-QeLEi4X7tcDP4tz3pkAajWTA\n",
            "[2023-08-01 04:48:33] Fine-tune costs $0.41\n",
            "[2023-08-01 04:48:34] Fine-tune enqueued. Queue number: 4\n",
            "[2023-08-01 04:49:09] Fine-tune is in the queue. Queue number: 3\n",
            "[2023-08-01 04:50:34] Fine-tune is in the queue. Queue number: 2\n",
            "[2023-08-01 04:50:40] Fine-tune is in the queue. Queue number: 1\n",
            "[2023-08-01 04:50:43] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-08-01 04:51:00] Fine-tune started\n",
            "[2023-08-01 04:52:20] Completed epoch 1/4\n",
            "[2023-08-01 04:52:39] Completed epoch 2/4\n",
            "[2023-08-01 04:52:58] Completed epoch 3/4\n",
            "[2023-08-01 04:53:17] Completed epoch 4/4\n",
            "[2023-08-01 04:53:33] Uploaded model: curie:ft-university-of-pennsylvania-2023-08-01-04-53-33\n",
            "[2023-08-01 04:53:34] Uploaded result file: file-2foVnAfDtAEf7Jr0pvV1XKEk\n",
            "[2023-08-01 04:53:34] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m curie:ft-university-of-pennsylvania-2023-08-01-04-53-33 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should copy down the fine-tune numbers which look like this:\n",
        "\n",
        "```\n",
        "Created fine-tune: ft-kloUh0jjVc6Jv8p9MfeGHd3s\n",
        "\n",
        "[2022-08-06 00:43:56] Uploaded model: davinci:ft-ccb-lab-members-2022-08-06-00-57-57\n",
        "```\n",
        "\n",
        "If you forget to write it down, you can list your fine-tuned runs and models this way. These model names aren't mneumonic, so it is probably a good idea to make a note on what your model's inputs and outputs are."
      ],
      "metadata": {
        "id": "CQ8j8VRVdfv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.list"
      ],
      "metadata": {
        "id": "seMeIwOAdgcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "856daf2e-eccc-4ff3-e21b-ac644d4d1dcf"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"object\": \"fine-tune\",\n",
            "      \"id\": \"ft-cmUUBGzD5BBVAN4pUlkK8baj\",\n",
            "      \"hyperparams\": {\n",
            "        \"n_epochs\": 4,\n",
            "        \"batch_size\": 1,\n",
            "        \"prompt_loss_weight\": 0.01,\n",
            "        \"learning_rate_multiplier\": 0.1\n",
            "      },\n",
            "      \"organization_id\": \"org-ltRdFFJJ31qmdCKTFNnrq2Ma\",\n",
            "      \"model\": \"ada\",\n",
            "      \"training_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-YxcULYofhyQUvK7mnYtmOJ4u\",\n",
            "          \"purpose\": \"fine-tune\",\n",
            "          \"filename\": \"newsela_sentences_finetuning_data.jsonl\",\n",
            "          \"bytes\": 26380,\n",
            "          \"created_at\": 1690413946,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"validation_files\": [],\n",
            "      \"result_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-xSdvBnrPKpYUgUEK52qxRMH6\",\n",
            "          \"purpose\": \"fine-tune-results\",\n",
            "          \"filename\": \"compiled_results.csv\",\n",
            "          \"bytes\": 20083,\n",
            "          \"created_at\": 1690421636,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"created_at\": 1690413947,\n",
            "      \"updated_at\": 1690421636,\n",
            "      \"status\": \"succeeded\",\n",
            "      \"fine_tuned_model\": \"ada:ft-university-of-pennsylvania-2023-07-27-01-33-55\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine-tune\",\n",
            "      \"id\": \"ft-ne3XYcUaogdZxdOsX9iugFcJ\",\n",
            "      \"hyperparams\": {\n",
            "        \"n_epochs\": 4,\n",
            "        \"batch_size\": 1,\n",
            "        \"prompt_loss_weight\": 0.01,\n",
            "        \"learning_rate_multiplier\": 0.1\n",
            "      },\n",
            "      \"organization_id\": \"org-ltRdFFJJ31qmdCKTFNnrq2Ma\",\n",
            "      \"model\": \"ada\",\n",
            "      \"training_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-Suir1SwDMPWijABI0j1eGmNa\",\n",
            "          \"purpose\": \"fine-tune\",\n",
            "          \"filename\": \"newsela_documents_finetuning_data.jsonl\",\n",
            "          \"bytes\": 200847,\n",
            "          \"created_at\": 1690445887,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"validation_files\": [],\n",
            "      \"result_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-Rwn2b5kCsF98PTOdUwXnXOMn\",\n",
            "          \"purpose\": \"fine-tune-results\",\n",
            "          \"filename\": \"compiled_results.csv\",\n",
            "          \"bytes\": 8990,\n",
            "          \"created_at\": 1690459426,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"created_at\": 1690445887,\n",
            "      \"updated_at\": 1690459427,\n",
            "      \"status\": \"succeeded\",\n",
            "      \"fine_tuned_model\": \"ada:ft-university-of-pennsylvania-2023-07-27-12-03-46\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine-tune\",\n",
            "      \"id\": \"ft-QeLEi4X7tcDP4tz3pkAajWTA\",\n",
            "      \"hyperparams\": {\n",
            "        \"n_epochs\": 4,\n",
            "        \"batch_size\": 1,\n",
            "        \"prompt_loss_weight\": 0.01,\n",
            "        \"learning_rate_multiplier\": 0.1\n",
            "      },\n",
            "      \"organization_id\": \"org-ltRdFFJJ31qmdCKTFNnrq2Ma\",\n",
            "      \"model\": \"curie\",\n",
            "      \"training_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-ymQeYDSa0DR43Qj2JCQIMaWK\",\n",
            "          \"purpose\": \"fine-tune\",\n",
            "          \"filename\": \"wikibio_finetuning_data.jsonl\",\n",
            "          \"bytes\": 130153,\n",
            "          \"created_at\": 1690857123,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"validation_files\": [],\n",
            "      \"result_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-2foVnAfDtAEf7Jr0pvV1XKEk\",\n",
            "          \"purpose\": \"fine-tune-results\",\n",
            "          \"filename\": \"compiled_results.csv\",\n",
            "          \"bytes\": 22182,\n",
            "          \"created_at\": 1690865613,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"created_at\": 1690857123,\n",
            "      \"updated_at\": 1690865614,\n",
            "      \"status\": \"succeeded\",\n",
            "      \"fine_tuned_model\": \"curie:ft-university-of-pennsylvania-2023-08-01-04-53-33\"\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"fine-tune\",\n",
            "      \"id\": \"ft-aFCx5KwX61Nq4pjz4xo66ckI\",\n",
            "      \"hyperparams\": {\n",
            "        \"n_epochs\": 4,\n",
            "        \"batch_size\": null,\n",
            "        \"prompt_loss_weight\": 0.01,\n",
            "        \"learning_rate_multiplier\": null\n",
            "      },\n",
            "      \"organization_id\": \"org-ltRdFFJJ31qmdCKTFNnrq2Ma\",\n",
            "      \"model\": \"davinci\",\n",
            "      \"training_files\": [\n",
            "        {\n",
            "          \"object\": \"file\",\n",
            "          \"id\": \"file-6luaAg2w6JLwNsMY0qrW097q\",\n",
            "          \"purpose\": \"fine-tune\",\n",
            "          \"filename\": \"wikibio_parser_finetuning_data.jsonl\",\n",
            "          \"bytes\": 130153,\n",
            "          \"created_at\": 1690861685,\n",
            "          \"status\": \"processed\",\n",
            "          \"status_details\": null\n",
            "        }\n",
            "      ],\n",
            "      \"validation_files\": [],\n",
            "      \"result_files\": [],\n",
            "      \"created_at\": 1690861685,\n",
            "      \"updated_at\": 1690861685,\n",
            "      \"status\": \"pending\",\n",
            "      \"fine_tuned_model\": null\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can run your fine tuned model in the OpenAI Playground.  After the model is finished finetuning you'll find it in the Engine dropdown menu (you might need to press reload in your browser for your fine-tuned model to appear).\n",
        "\n",
        "## Call your fine-tuned model from the OpenAI API\n",
        "\n",
        "Alternately, you can use your fine tuned model via the API by specifying it as the model.  Here's an example:"
      ],
      "metadata": {
        "id": "L_UvcHRUdnWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bio(attributes, finetuned_model):\n",
        "  response = openai.Completion.create(\n",
        "      model=finetuned_model,\n",
        "      prompt=\"{attributes}\\n---\\n\".format(attributes=attributes),\n",
        "      temperature=0.7,\n",
        "      max_tokens=500,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"###\"]\n",
        "      )\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "# Replace with your model's name\n",
        "finetuned_model = \"curie:ft-university-of-pennsylvania-2023-08-01-04-53-33\""
      ],
      "metadata": {
        "id": "sM7AvrzqdjKU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attributes = \"\"\"\n",
        "notable_type: computer scienist\n",
        "alma_mater: Stanford University (BS in Symbolic Systems), University of Edinburgh (PhD in Informatics)\n",
        "birth_place: California\n",
        "children: 2\n",
        "gender: male\n",
        "main_interests: Artificial Intelligence, Natural Language Processing\n",
        "name: Chris Callison-Burch\n",
        "nationality: American\n",
        "notable_works: Moses: Open source toolkit for statistical machine translation, The Paraphrase Database (PPDB)\n",
        "occupation: professor\n",
        "courses_taught: AI, Crowdsourcing and NLP\n",
        "enrollment_in_most_popular_course: 570 students\n",
        "institution: University of Pennsylvania\n",
        "\"\"\"\n",
        "\n",
        "biography = generate_bio(attributes, finetuned_model)\n",
        "print(attributes)\n",
        "print('---')\n",
        "biography"
      ],
      "metadata": {
        "id": "lMorpMvta66Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "1b175707-5bc7-4a9a-cf48-c43310675592"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "notable_type: computer scienist\n",
            "alma_mater: Stanford University (BS in Symbolic Systems), University of Edinburgh (PhD in Informatics)\n",
            "birth_place: California\n",
            "children: 2\n",
            "gender: male\n",
            "main_interests: Artificial Intelligence, Natural Language Processing\n",
            "name: Chris Callison-Burch\n",
            "nationality: American\n",
            "notable_works: Moses: Open source toolkit for statistical machine translation, The Paraphrase Database (PPDB)\n",
            "occupation: professor\n",
            "courses_taught: AI, Crowdsourcing and NLP\n",
            "enrollment_in_most_popular_course: 570 students\n",
            "institution: University of Pennsylvania\n",
            "\n",
            "---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Biography: Chris Callison-Burch is an American professor at the University of Pennsylvania. He is a professor in the Department of Linguistics and in the Artificial Intelligence Laboratory. He completed his BS in Symbolic Systems from Stanford University and his PhD in Informatics from the University of Edinburgh. His notable works include Moses: Open source toolkit for statistical machine translation, The Paraphrase Database (PPDB). He has also worked in the fields of crowdsourcing and natural language processing. Callison-Burch was born in California.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze your model's output"
      ],
      "metadata": {
        "id": "ppP6tS3FjBGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes the model will add facts that are not present in the attributes.  For instance, one time it said\n",
        "> He was a member of the research staff at IBM Research in Yorktown Heights.\n",
        "\n",
        "which is not correct. Another time it said\n",
        "> His most popular course was on AI, which had 570 students.\n",
        "\n",
        "which is correct, but not specified in the attirbutes.\n",
        "\n",
        "Try running your own fine-tuned model until it produces something that wasn't licensed by the attributes.\n",
        "\n",
        "Save the good runs and the bad run below."
      ],
      "metadata": {
        "id": "Ith4CGAVdGfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generations_with_correct_facts = [\n",
        "   \"\"\" Biography: Chris Callison-Burch is an American professor of computer science and a professor of engineering \\\n",
        "   at the University of Pennsylvania. He is best known for his work in machine learning and natural language processing. \\\n",
        "   His notable works include Moses: Open source toolkit for statistical machine translation, \\\n",
        "   The Paraphrase Database (PPDB). He was born in California. He attended Stanford University (BS in Symbolic Systems), \\\n",
        "   University of Edinburgh (PhD in Informatics). Callison-Burch was born in California..\n",
        "   \"\"\",\n",
        "\n",
        "   \"\"\" Biography: Chris Callison-Burch is an artificial intelligence researcher and professor at the University of Pennsylvania. \\\n",
        "   He is best known for his work on Moses, a toolkit for statistical machine translation. \\\n",
        "   He has also worked on The Paraphrase Database (PPDB), a web-based system that provides paraphrasing services for researchers. \\\n",
        "   He graduated from Stanford University and the University of Edinburgh with a BS in Symbolic Systems and a PhD in Informatics. \"\"\",\n",
        "                       ]\n",
        "\n",
        "generation_with_incorrect_facts_= \"\"\"\n",
        "Biography: Chris Callison-Burch (born August 20, 1969) is an American professor at the University of Pennsylvania. \\\n",
        "He is best known for his work in artificial intelligence and natural language processing. He was born in California. \\\n",
        "He attended Stanford University and the University of Edinburgh, where he earned a BS in Symbolic Systems, \\\n",
        "and a PhD in Informatics. His notable works are Moses: Open source toolkit for statistical machine translation, \\\n",
        "The Paraphrase Database (PPDB) and AI, Crowdsourcing and NLP. Callison-Burch is a professor at the University of Pennsylvania. \\\n",
        "He has taught there since 1999. He is the author of the textbook Artificial Intelligence: A Modern Approach. \\\n",
        "He is also the author of the book Artificial Intelligence: A Modern Approach. \\\n",
        "He is a well known for his work in artificial intelligence and natural language processing. \\\n",
        "He attended Stanford University and the University of Edinburgh, where he earned a BS in Symbolic Systems, \\\n",
        "and a PhD in Informatics. His notable works are Moses: Open source toolkit for statistical machine translation, \\\n",
        "The Paraphrase Database (PPDB) and AI, Crowdsourcing and NLP. His notable works are Moses: \\\n",
        "Open source toolkit for statistical machine translation, The Paraphrase Database (PPDB) and AI, \\\n",
        "Crowdsourcing and NLP. His notable works are Moses: Open source toolkit for statistical machine translation, \\\n",
        "The Paraphrase Database (PPDB) and AI, Crowdsourcing and NLP. His notable works are Moses: \\\n",
        "Open source toolkit for statistical machine translation, The Paraphrase Database (PPDB) and AI, \\\n",
        "Crowdsourcing and NLP. His notable works are Moses: Open source toolkit for statistical machine translation, \\\n",
        "The Paraphrase Database (PPDB) and AI, Crowdsourcing and NLP.\n",
        "\"\"\"\n",
        "\n",
        "incorrect_facts = [\n",
        "    \"\"\" Callison-Burch is a professor at the University of Pennsylvania. He has taught there since 1999.\"\"\",\n",
        "]"
      ],
      "metadata": {
        "id": "qdFONhDMdWw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tune a New Model\n",
        "\n",
        "Now that you've seen an example of how to do fine-tuning with the OpenAI API, let's have you write code to fine-tune your own model.\n",
        "\n",
        "For this model, I'd like you to do the reverse direction of what we just did.  Given a Wikipedia Biograph like this:\n",
        "\n",
        "> Jill Tracy Jacobs Biden (born June 3, 1951) is an American educator and the current first lady of the United States as the wife of President Joe Biden. She was the second lady of the United States from 2009 to 2017. Since 2009, Biden has been a professor of English at Northern Virginia Community College.\n",
        "\n",
        "> She has a bachelor's degree in English and a doctoral degree in education from the University of Delaware, as well as master's degrees in education and English from West Chester University and Villanova University. She taught English and reading in high schools for thirteen years and instructed adolescents with emotional disabilities at a psychiatric hospital. From 1993 to 2008, Biden was an English and writing instructor at Delaware Technical & Community College. Biden is thought to be the first wife of a vice president or president to hold a paying job during her husband's tenure.\n",
        "\n",
        "> Born in Hammonton, New Jersey, she grew up in Willow Grove, Pennsylvania. She married Joe Biden in 1977, becoming stepmother to Beau and Hunter, his two sons from his first marriage. Biden and her husband also have a daughter together, Ashley Biden, born in 1981. She is the founder of the Biden Breast Health Initiative non-profit organization, co-founder of the Book Buddies program, co-founder of the Biden Foundation, is active in Delaware Boots on the Ground, and with Michelle Obama is co-founder of Joining Forces. She has published a memoir and two children's books.\n",
        "\n",
        "Your model should output something like this:\n",
        "```\n",
        "notable_type: First Lady of the United States\n",
        "name: Jill Biden\n",
        "gender: female\n",
        "nationality: American\n",
        "birth_date: 03 June 1951\n",
        "birth_place: Hammonton, New Jersey\n",
        "alma_mater: University of Delaware\n",
        "occupation: professor of English at Northern Virginia Community College\n",
        "notable_works: children's books and memoir\n",
        "main_interests: education, literacy, women's health\n",
        "partner: Joe Biden\n",
        "children: Ashley Biden, Beau Biden (stepson), Hunter Biden (stepson)\n",
        "```\n"
      ],
      "metadata": {
        "id": "yMEUR3f8eh0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def create_wikibio_parser_finetuning_data(wikibios, fine_tuning_filename):\n",
        "  # TODO - write your fine-tuning function\n",
        "  fine_tuning_data = []\n",
        "\n",
        "  for attributes, bio in wiki_bios:\n",
        "    completion = \"{attributes}\\n---\\n###\".format(attributes=attributes)\n",
        "    prompt = \"Biography: {bio}\\n\".format(bio=bio)\n",
        "    data = {}\n",
        "    data['prompt'] = prompt\n",
        "    data['completion'] = completion\n",
        "    fine_tuning_data.append(data)\n",
        "\n",
        "  random.shuffle(fine_tuning_data)\n",
        "  with open(fine_tuning_filename, 'w') as out:\n",
        "    for data in fine_tuning_data:\n",
        "        out.write(json.dumps(data))\n",
        "        out.write('\\n')\n",
        "\n",
        "fine_tuning_filename='wikibio_parser_finetuning_data.jsonl'\n",
        "create_wikibio_parser_finetuning_data(wiki_bios, fine_tuning_filename)"
      ],
      "metadata": {
        "id": "fnR7bToueV50"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head '{fine_tuning_filename}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt8usqpT-vlG",
        "outputId": "36f8e665-1fcd-4a3a-d849-bf0377532dda"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"prompt\": \"Biography: Zlata Toth is a Slovakian artist who specializes in painting, drawing, and performance. They attended Budapest Academy of Fine Arts and Toth has notable works which include Afro Artworks of the Unknown Master, Self-Portrait, Birth of the Universe, and Cubist Landscape and Toth is a member of the Cercle International d'Art Granduc. Toth received Herder Prize (2005) and they were born to Andre Toth, Gizella Toth. Toth is married to Maria Vazquez and together they had three children: Andrea Vazquez Toth, Alicia Vazquez Toth, and Antonio Vazquez Toth.\\n\", \"completion\": \"notable_type: artist\\nname: Zlata Toth\\ngender: non-binary\\nnationality: Slovakian\\nbirth_date: 05 April 1976\\nbirth_place: Bratislava, Slovakia\\nknown_for: painting\\nnotable_works: Afro Artworks of the Unknown Master, Self-Portrait, Birth of the Universe, and Cubist Landscape\\nalma_mater: Budapest Academy of Fine Arts\\nawards: Herder Prize (2005)\\nelected: Cercle International d'Art Granduc\\nmother: Gizella Toth\\nfather: Andre Toth\\npartner: Maria Vazquez\\nchildren: Andrea Vazquez Toth, Alicia Vazquez Toth, and Antonio Vazquez Toth\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Vasilika Hoxhaj was a librarian at the University of Prishtina, Serbia in Kosovo. Hoxhaj was born on May 31, 1970 in Prishtina, Yugoslavia to mother Maria Hoxhaj. Hoxhaj began working as a librarian at the University of Prishtina. Hoxhaj was recruited by the CIA and Mossad. Her codename was The Librarian.\\n\", \"completion\": \"notable_type: spy\\nname: Vasilika Hoxhaj\\ngender: female\\nnationality: Albanian\\nbirth_date: 31 May 1970\\nbirth_place: Prishtina, Yugoslavia\\nalma_mater: University of Prishtina, Serbia\\noccupation: librarian\\ncodename: The Librarian\\nallegiance: CIA, Mossad\\nmother: Maria Hoxhaj\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Esther Kulapulapulaomeaamao (aka Esther Tua`a`e, Esther Kulapulapula) was born on July 21, 1979 in Auckland, New Zealand. Her mother, Meleana Tua`a`e and her father, Leimamo Tua`a`e . She attended the University of California at San Diego. She has been performing and recording music since 1993 till present and she has performed with Robert \\\"Sly Stone\\\" Reed. Esther's genres are blues, gospel, jazz. Her home town is Tonga,New Zealand,Oakland, California. Her labels are Pacific Records, Rounder Records, New International Records, Paradisec Records. Esther's awards are Grammy Award for Best Reggae Album nominated. he was married to Leimamo`s second wife, Lupe`a. and her children are Leimami, Leighton, Lalena.\\n\", \"completion\": \"notable_type: musician\\nname: Esther Tua`a`e\\nbirth_name: Esther Kulapulapulaomeaamao\\nalias: Esther T\\ngender: female\\nbirth_date: 21 July 1979\\nbirth_place: Auckland, New Zealand\\ndeath_date: unknown\\ndeath_place: unkown\\ndeath_cause: unknown\\ninstrument: guitar, vocals\\ngenre: blues, gospel, jazz\\nhometown: Tonga>New Zealand>Oakland, California\\nnationality: Samoan\\ncitizenship: Samoan\\neducation: University of California at San Diego\\nyears_active: 1993-present\\nlabel: Pacific Records, Rounder Records, New International Records, Paradisec Records\\nassociated_acts: Robert \\\"Sly Stone\\\" Reed\\nawards: Grammy Award for Best Reggae Album nominated\\nmother: Meleana Tua`a`e\\nfather: Leimamo Tua`a`e\\npartner: Leimamo`s second wife, Lupe`a\\nchildren: Leimami, Leighton, Lalena.\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Zulma Hern\\u00e1ndez (15 October 1925 - 27 January 2019) was a Costa Rican anthropologist born to Josefina Alfaro and Ricardo Montero. Hern\\u00e1ndez went to Harvard University and completed PhD in Anthropology. Hern\\u00e1ndez's genre was anthropology, memoir. Hern\\u00e1ndez received Order of the Aztec Eagle, Padma Bhushan, National Prize for Medicine (1991). Hern\\u00e1ndez was married to Abelino Mazariegos and together ahd 4 children. Hern\\u00e1ndez died on January 27, 2019 in San Jos\\u00e9, Costa Rica of natural causes and was laid to rest in Hospital Calder\\u00f3n Guardia.\\n\", \"completion\": \"notable_type: writer\\nname: Zulma Hern\\u00e1ndez\\ngender: non-binary\\nnationality: Costa Rican\\nbirth_date: 15 October 1925\\nbirth_place: Alajuela, Costa Rica\\ndeath_date: January 27, 2019\\ndeath_place: San Jos\\u00e9, Costa Rica\\ndeath_cause: natural causes\\nresting_place: Hospital Calder\\u00f3n Guardia\\nalma_mater: Harvard University\\neducation: PhD in Anthropology\\noccupation: anthropologist\\nlanguage: Spanish, English\\ngenre: anthropology, memoir\\nawards: Order of the Aztec Eagle, Padma Bhushan, National Prize for Medicine (1991)\\nmother: Josefina Alfaro\\nfather: Ricardo Montero\\npartner: Abelino Mazariegos\\nchildren: 4\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Igor Kyrz is a Kyrgyzstani wrestler. He was born in Bishkek, Kyrgyzstan on May 26, 1980. Kyrz is a heavyweight wrestler. Igor competed at the 2008 Summer Olympics, in the men's Greco-Roman 120 kg event. He actively participated from 2005 to 2015 and later retired in 2015. Igor was a height of 6ft, 2in and 230lb and trained under Daulet Turlybekov. He palyed for the national team Kyrgyzstan. Igor was son of Nurgul Tursunkulova and Janibek Tursunkulov.\\n\", \"completion\": \"notable_type: athlete\\nname: Igor Kyrz\\ngender: male\\nnationality: Kyrgyzstani\\nbirth_date: 26 May 1980\\nbirth_place: Bishkek, Kyrgyzstan\\ndeath_date: 16 June 2018\\ndeath_place: Bishkek, Kyrgyzstan\\ndeath_cause: stroke\\nresting_place: Bishkek, Kyrgyzstan\\nsport: wrestling\\ncountry: Kyrgyzstan\\nhometown: Jalalabad, Afghanistan\\ncitizenship: Kyrgyzstani\\nevent: wrestling\\nposition: heavyweight\\nyears_active: 2005-2015\\nretired: 2015\\nheight: 6ft, 2in\\nweight: 230lb\\ncoach: Daulet Turlybekov\\nnational_team: Kyrgyzstan\\nolympics: 2008 Summer Olympics - Men's Greco-Roman 120 kg\\nmother: Nurgul Tursunkulova\\nfather: Janibek Tursunkulov\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Samia Ismail (27 April 1851 - 9 April 1912) was an Algerian feminist, nationalist, writer, and activist. Ismail was a co-founder of the Union Nationale des Femmes Alg\\u00e9riennes (UNFA), the first Algerian women's rights organization. She wrote extensively on women's rights, women's rights, women's access to education, Algerian feminism, Algerian nationalism. Her notable work was De l'\\u00e9mancipation de la femme musulmane; Leila; L'H\\u00e9ritage et l'h\\u00e9riti\\u00e8re and she was born to Fatima Ahmed El Fihul, Ahmed El Fihul and married to Pierre Levie. She attended the University of Algiers and her traditional movements were Algerian feminist philosopher, advocate for a participatory rather than receptive feminism. Samia died on 9 April 1912 due to tuberculosis and buried in Saint John the Baptist church, Constantine, Algeria.\\n\", \"completion\": \"notable_type: theologian\\nname: Samia Ismail\\ngender: female\\nnationality: Algerian\\nbirth_date: 27 April 1851\\nbirth_place: Algeria\\ndeath_date: 9 April 1912\\ndeath_place: Constantine, Algeria\\ndeath_cause: tuberculosis\\nresting_place: Saint John the Baptist church, Constantine, Algeria\\nalma_mater: University of Algiers\\noccupation: author, writer, teacher, philosopher, theologian\\ntradition_movement: Algerian feminist philosopher, advocate for a participatory rather than receptive feminism\\nnotable_works: De l'\\u00e9mancipation de la femme musulmane; Leila; L'H\\u00e9ritage et l'h\\u00e9riti\\u00e8re\\nmain_interests: women's rights, women's access to education, Algerian feminism, Algerian nationalism\\nmother: Fatima Ahmed El Fihul\\nfather: Ahmed El Fihul\\npartner: Pierre Levie\\nchildren: none\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Yvesita Alcivar was born in Valleseco, Tenerife, 26 October 1854. She was a chemist in the fields of biochemistry, pharmacology, neuroscience. She was known for The Ki\\u0161ka Method. She studied at Yale university. She worked in the institutions Rockefeller University, Yale University School of Medicine, Institute for Advanced Study, Institute for Cancer Research (Philadelphia). Her influences were Emil Fischer, Arthur Kornberg, Severo Ochoa, Teofilo Folche, Paul Lauterbur, James Watson, William Halsted, Richard Feynman, Otto Stern, Albert Einstein, Vincent Van Gogh. She was born to Emilia Kishka and Aristides Alcivar. She was married to Emilio Calder\\u00f3n and had three children, Yves, \\u00c9milio, F\\u00e9lix. She died on 24 January 1945, San Juan, Puerto Rico.\\n\", \"completion\": \"notable_type: scientist\\nname: Yvesita Alcivar\\ngender: female\\nbirth_date: 26 October 1854\\nbirth_place: Valleseco, Tenerife\\ndeath_date: 24 January 1945\\ndeath_place: San Juan, Puerto Rico\\noccupation: chemist\\nfields: biochemistry, pharmacology, neuroscience\\nknown_for: The Ki\\u0161ka Method\\nhometown: San Juan, Puerto Rico\\nnationality: Venezuelan\\ncitizenship: American\\nalma_mater: Yale university\\nthesis_title: On the Synthetic Transformation of the Amino Acid Hypoxanthine\\nthesis_year: 1879\\ndoctoral_advisor: Nathaniel Lord Britton\\nawards: Nobel Prize for Physiology or Medicine in 1945\\ninstitutions: Rockefeller University, Yale University School of Medicine, Institute for Advanced Study, Institute for Cancer Research (Philadelphia)\\nnotable_students: Ira Retzius\\ninfluences: Emil Fischer, Arthur Kornberg, Severo Ochoa, Teofilo Folche, Paul Lauterbur, James Watson, William Halsted, Richard Feynman, Otto Stern, Albert Einstein, Vincent Van Gogh\\nmother: Emilia Kishka\\nfather: Aristides Alcivar\\npartner: Emilio Calder\\u00f3n\\nchildren: Yves, \\u00c9milio, F\\u00e9lix\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Min Lwin (18 March 1989 Yangon, Burma) is a Burmese political activist, YouTuber, writer, and activist. Lwin was born in Yangon, Burma to mother Aung San Suu Kyi and father Aung San. Lwin is non-binary. Lwin founded the political activism website MinnLwinThawKyu.com and started a blog called Minn Lwin Thaw Kyu, which was considered the most popular Burmese website for 18 years straight. They studied political science at ohio state in 2006. They held allegiance towards The people of Burma.\\n\", \"completion\": \"notable_type: spy\\nname: Min Lwin\\ngender: non-binary\\nnationality: Burmese\\nbirth_date: 18 March 1989\\nbirth_place: Yangon, Burma\\nserviceyears: 1996-2020\\nknown_for: founded Burmese political activism website MinnLwinThawKyu.com that was considered the most popular Burmese website for 18 years straight\\nalma_mater: Political Science, Ohio State, 2006\\noccupation: Activist, YouTuber, writer\\nallegiance: the people (Burmese)\\nagency: Self\\nmother: Aung San Suu Kyi\\nfather: Aung San\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Johann Schmidt (01 September 1993 - n/a) was an Austrian painter. Schmidt was born in New York City, and attended the Carnegie Mellon School of Art. Johann is best known for his portraiture. They received a Carnegie award and a Turner award. Johann was elected President of the Painting Guild of New York. Schmidt's mother is Agnes Schmidt, and father is Heinrich Kohler. Schmidt is survived by partner Julia Weber and their children Johann, Sebastian, and Anna.\\n\", \"completion\": \"notable_type: artist\\nname: Johann Schmidt\\ngender: non-binary\\nnationality: Austrian\\nbirth_date: 01 September 1993\\nbirth_place: New York City\\nknown_for: portraiture\\nnotable_works: The Blue Lady, Mrs. Roosevelt\\nalma_mater: Carnegie Mellon School of Art\\nawards: Carnegie, Turner\\nelected: President of the Painting Guild of New York\\nmother: Agnes Schmidt\\nfather: Heinrich Kohler\\npartner: Julia Weber\\nchildren: Johann, Sebastian, Anna\\n---\\n###\"}\n",
            "{\"prompt\": \"Biography: Isabella Norrstr\\u00f6m (born 14 April 1889) was a Swedish mountaineer. She was born in the port city of Gothenburg, Sweden to Kerstin and Henning Norrstr\\u00f6m. She started climbing when she was 12 years old, and her notable works include Matterhorn, the Dom, La Luz and Kangchenjunga. Isabella had partnerships with Tom K\\u00f6rling. Isabella was married to Tom K\\u00f6rling and together had two sons. Isabella died on 30 November 1928 in Kangchenjunga of ice axe fell from her hands due to exhaustion and her body disappeared into a deep crevasse and was laid to rest in north face of Kangchenjunga.\\n\", \"completion\": \"notable_type: mountaineer\\nname: Isabella Norrstr\\u00f6m\\ngender: female\\nnationality: Swedish\\nbirth_date: 14 April 1889\\nbirth_place: the port city of Gothenburg\\ndeath_date: 30 November 1928\\ndeath_place: Kangchenjunga\\ndeath_cause: ice axe fell from her hands due to exhaustion and her body disappeared into a deep crevasse\\nresting_place: north face of Kangchenjunga\\nstart_age: 12\\nnotable_ascents: Matterhorn, the Dom, La Luz\\nfinal_ascent: Kangchenjunga\\npartnerships: Tom K\\u00f6rling\\nmother: Kerstin Norrstr\\u00f6m\\nfather: Henning Norrstr\\u00f6m\\npartner: Tom K\\u00f6rling\\nchildren: two sons\\n---\\n###\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!openai api fine_tunes.create -t '{fine_tuning_filename}' -m curie\n",
        "!openai api fine_tunes.create -t '{fine_tuning_filename}' -m davinci"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzUEaol5eoPG",
        "outputId": "98204ec6-2613-443f-a3d0-d6f45b02ff19"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/130k [00:00<?, ?it/s]\rUpload progress: 100% 130k/130k [00:00<00:00, 70.3Mit/s]\n",
            "Uploaded file from wikibio_parser_finetuning_data.jsonl: file-6luaAg2w6JLwNsMY0qrW097q\n",
            "Created fine-tune: ft-aFCx5KwX61Nq4pjz4xo66ckI\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-08-01 03:48:05] Created fine-tune: ft-aFCx5KwX61Nq4pjz4xo66ckI\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-aFCx5KwX61Nq4pjz4xo66ckI\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-aFCx5KwX61Nq4pjz4xo66ckI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3bqmZ9gN8O7",
        "outputId": "f8537978-fb23-4158-ee0d-d1819b37db1b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-08-01 03:48:05] Created fine-tune: ft-aFCx5KwX61Nq4pjz4xo66ckI\n",
            "[2023-08-01 07:25:52] Fine-tune costs $4.07\n",
            "[2023-08-01 07:25:52] Fine-tune enqueued. Queue number: 1\n",
            "[2023-08-01 07:33:03] Fine-tune is in the queue. Queue number: 0\n",
            "[2023-08-01 07:36:45] Fine-tune started\n",
            "[2023-08-01 07:40:09] Completed epoch 1/4\n",
            "[2023-08-01 07:41:01] Completed epoch 2/4\n",
            "[2023-08-01 07:41:51] Completed epoch 3/4\n",
            "[2023-08-01 07:42:41] Completed epoch 4/4\n",
            "[2023-08-01 07:43:34] Uploaded model: davinci:ft-university-of-pennsylvania-2023-08-01-07-43-33\n",
            "[2023-08-01 07:43:35] Uploaded result file: file-ai7B4SByg0t2R5A7VapBhUTG\n",
            "[2023-08-01 07:43:35] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m davinci:ft-university-of-pennsylvania-2023-08-01-07-43-33 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_bio(biography, finetuned_bio_parser_model):\n",
        "\n",
        "  # TODO call the API with your fine-tuned model, return a string representing the attributes\n",
        "  response = openai.Completion.create(\n",
        "      model=finetuned_bio_parser_model,\n",
        "      prompt=\"Biography: {bio}\\n\".format(bio=biography),\n",
        "      temperature=0.7,\n",
        "      max_tokens=500,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"###\"]\n",
        "      )\n",
        "\n",
        "  return response['choices'][0]['text'].strip()\n",
        "\n",
        "\n",
        "finetuned_bio_parser_model=\"davinci:ft-university-of-pennsylvania-2023-08-01-07-43-33\""
      ],
      "metadata": {
        "id": "KrqNIFPFmtEQ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test your parser\n",
        "\n",
        "Next we will test your parser.  This will involve calling your `parse_bio` function about 250 times, so be sure that you've got it properly debugged and working before running this code."
      ],
      "metadata": {
        "id": "G9V3zLFmqEbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_test.json"
      ],
      "metadata": {
        "id": "v9a9CvE9p8D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c53822-71ee-4f8e-da05-178d61dfe601"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-01 07:48:00--  https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 665457 (650K) [text/plain]\n",
            "Saving to: ‘SynthBio_test.json’\n",
            "\n",
            "\rSynthBio_test.json    0%[                    ]       0  --.-KB/s               \rSynthBio_test.json  100%[===================>] 649.86K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-08-01 07:48:00 (14.8 MB/s) - ‘SynthBio_test.json’ saved [665457/665457]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_wiki_bio_test_set(filename='SynthBio_test.json', max_test_items=10, randomized=True):\n",
        "  \"\"\"\n",
        "  Loads our wikibio test set, and returns a list of tuples\n",
        "  biographies (text), attributes (dictionaires)\n",
        "  \"\"\"\n",
        "  with open(filename) as f:\n",
        "    synth_bio_data = json.load(f)\n",
        "  bios = []\n",
        "  for data in synth_bio_data:\n",
        "    notable_type = data['notable_type']\n",
        "    attributes = data['attrs']\n",
        "    attributes['notable_type'] = notable_type\n",
        "    biography = data['biographies'][0]\n",
        "    bios.append((biography, attributes))\n",
        "  return bios[:min(max_test_items, len(bios))]\n",
        "\n",
        "\n",
        "def convert_to_dict(predcited_attributes_txt):\n",
        "  \"\"\"\n",
        "  Converts predicted attributes from text format into a dictionary.\n",
        "  \"\"\"\n",
        "  predicted_attributes = {}\n",
        "  atrr_lst = predcited_attributes_txt.split('\\n')\n",
        "  for i in range(len(atrr_lst)-1):\n",
        "    line = atrr_lst[i]\n",
        "    attribute, value = line.split(':')\n",
        "    predicted_attributes[attribute.strip()] = value.strip()\n",
        "  return predicted_attributes\n",
        "\n"
      ],
      "metadata": {
        "id": "Ncu11s25qdoV"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function for computing precision, recall and f-score."
      ],
      "metadata": {
        "id": "giP9b76iFjEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def update_counts(gold_attributes, predicted_attributes, true_positives, false_positives, false_negatives, all_attributes):\n",
        "  # Compute true positives and false negatives\n",
        "  for attribute in gold_attributes:\n",
        "    all_attributes[attribute] += 1\n",
        "    if attribute in predicted_attributes:\n",
        "      # some attributes have multiple values.\n",
        "      gold_values = gold_attributes[attribute].split(',')\n",
        "      for value in gold_values:\n",
        "        if value.strip() in predicted_attributes[attribute]:\n",
        "          true_positives[attribute] += 1\n",
        "        else:\n",
        "          false_negatives[attribute] += 1\n",
        "    else:\n",
        "      false_negatives[attribute] += 1\n",
        "  # Compute false positives\n",
        "  for attribute in predicted_attributes:\n",
        "    if attribute not in gold_attributes:\n",
        "      all_attributes[attribute] += 1\n",
        "    if not attribute in gold_values:\n",
        "      false_positives[attribute] += 1\n",
        "    else:\n",
        "      # some attributes have multiple values.\n",
        "      predicted_values = predicted_attributes[attribute].split(',')\n",
        "      for value in predicted_values:\n",
        "        if value.strip() not in gold_values[attribute]:\n",
        "          false_positives[attribute] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "8PvGbJYKrEq7"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_on_test_set(finetuned_bio_parser_model, wiki_bio_test, threshold_count = 5):\n",
        "  \"\"\"\n",
        "  Computer the precision, recall and f-score for each of the attributes\n",
        "  that appears more than the treshold count\n",
        "  \"\"\"\n",
        "  true_positives = Counter()\n",
        "  false_positives = Counter()\n",
        "  false_negatives = Counter()\n",
        "  all_attributes = Counter()\n",
        "\n",
        "  for bio, gold_attributes in wiki_bio_test:\n",
        "    predicted_attributes = convert_to_dict(parse_bio(bio, finetuned_bio_parser_model))\n",
        "    update_counts(gold_attributes, predicted_attributes, true_positives, false_positives, false_negatives, all_attributes)\n",
        "\n",
        "  average_precision = 0\n",
        "  average_recall = 0\n",
        "  total = 0\n",
        "\n",
        "  for attribute in all_attributes:\n",
        "    if all_attributes[attribute] < threshold_count:\n",
        "      continue\n",
        "    print(attribute.upper())\n",
        "    try:\n",
        "      precision = true_positives[attribute] / (true_positives[attribute] + false_positives[attribute])\n",
        "    except:\n",
        "      precision = 0.0\n",
        "    try:\n",
        "      recall = true_positives[attribute] / (true_positives[attribute] + false_negatives[attribute])\n",
        "    except:\n",
        "      recall = 0.0\n",
        "    print(\"precision:\", precision)\n",
        "    print(\"recall:\", recall)\n",
        "    print(\"f-score:\", (precision+recall)/2)\n",
        "    print('---')\n",
        "    average_precision += precision\n",
        "    average_recall += recall\n",
        "    total += 1\n",
        "\n",
        "  print(\"AVERAGE\")\n",
        "  average_precision = average_precision/total\n",
        "  average_recall = average_recall/total\n",
        "  print(\"precision:\", average_precision)\n",
        "  print(\"recall:\", average_recall)\n",
        "  print(\"f-score:\", (average_precision+average_recall)/2)\n",
        "  print('---')\n"
      ],
      "metadata": {
        "id": "M5UXVTgaGHBD"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you would like to evaluate on the full test set, there are 237 test items.  You can set `max_test_items=237`.  Doing so will call your `parse_bio` function about 237 times, so be sure that you've got it properly debugged and working before running this code."
      ],
      "metadata": {
        "id": "fBCI95rQI8gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testset_filename='SynthBio_test.json'\n",
        "max_test_items=10\n",
        "wiki_bio_test = load_wiki_bio_test_set(testset_filename, max_test_items)\n",
        "evaluate_on_test_set(finetuned_bio_parser_model, wiki_bio_test, threshold_count = 5)"
      ],
      "metadata": {
        "id": "BDSuk0AWGlOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88dd42d-e14f-479a-cf71-95c29e8f01fc"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\n",
            "precision: 0.4444444444444444\n",
            "recall: 0.8\n",
            "f-score: 0.6222222222222222\n",
            "---\n",
            "GENDER\n",
            "precision: 0.5\n",
            "recall: 1.0\n",
            "f-score: 0.75\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.47368421052631576\n",
            "recall: 0.9\n",
            "f-score: 0.6868421052631579\n",
            "---\n",
            "BIRTH_DATE\n",
            "precision: 0.47368421052631576\n",
            "recall: 0.9\n",
            "f-score: 0.6868421052631579\n",
            "---\n",
            "BIRTH_PLACE\n",
            "precision: 0.6153846153846154\n",
            "recall: 0.9411764705882353\n",
            "f-score: 0.7782805429864253\n",
            "---\n",
            "KNOWN_FOR\n",
            "precision: 0.5454545454545454\n",
            "recall: 0.6666666666666666\n",
            "f-score: 0.606060606060606\n",
            "---\n",
            "ALMA_MATER\n",
            "precision: 0.5625\n",
            "recall: 0.6923076923076923\n",
            "f-score: 0.6274038461538461\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.45454545454545453\n",
            "recall: 0.5555555555555556\n",
            "f-score: 0.5050505050505051\n",
            "---\n",
            "MOTHER\n",
            "precision: 0.4117647058823529\n",
            "recall: 0.7\n",
            "f-score: 0.5558823529411765\n",
            "---\n",
            "FATHER\n",
            "precision: 0.35714285714285715\n",
            "recall: 0.5555555555555556\n",
            "f-score: 0.4563492063492064\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.4117647058823529\n",
            "recall: 0.875\n",
            "f-score: 0.6433823529411764\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.5\n",
            "recall: 0.5882352941176471\n",
            "f-score: 0.5441176470588236\n",
            "---\n",
            "NOTABLE_TYPE\n",
            "precision: 0.47368421052631576\n",
            "recall: 0.9\n",
            "f-score: 0.6868421052631579\n",
            "---\n",
            "DEATH_DATE\n",
            "precision: 0.4\n",
            "recall: 0.5714285714285714\n",
            "f-score: 0.4857142857142857\n",
            "---\n",
            "DEATH_PLACE\n",
            "precision: 0.625\n",
            "recall: 1.0\n",
            "f-score: 0.8125\n",
            "---\n",
            "DEATH_CAUSE\n",
            "precision: 0.2222222222222222\n",
            "recall: 0.4\n",
            "f-score: 0.3111111111111111\n",
            "---\n",
            "RESTING_PLACE\n",
            "precision: 0.4\n",
            "recall: 0.8\n",
            "f-score: 0.6000000000000001\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.16666666666666666\n",
            "recall: 0.14285714285714285\n",
            "f-score: 0.15476190476190477\n",
            "---\n",
            "HOMETOWN\n",
            "precision: 0.2\n",
            "recall: 0.14285714285714285\n",
            "f-score: 0.17142857142857143\n",
            "---\n",
            "AVERAGE\n",
            "precision: 0.43357593943181366\n",
            "recall: 0.6911389522070636\n",
            "f-score: 0.5623574458194386\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in result.split('\\n'):\n",
        "  print(line.split(':'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5NYNAstF2cy",
        "outputId": "8e64496c-1a0e-400d-9376-cdf67824b375"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['notable_type', ' artist']\n",
            "['name', ' Igor Ivanov']\n",
            "['gender', ' male']\n",
            "['nationality', ' Russian']\n",
            "['birth_date', ' 18 October 1970']\n",
            "['birth_place', ' Moscow, Russia']\n",
            "['death_cause', ' none']\n",
            "['known_for', ' oil paintings of portraits, city scenes, still lifes, and flowers']\n",
            "['notable_works', ' Portraits of Celebrities, Still Life with Flowers, Flowers and Fruit and movement realism']\n",
            "['movement', ' realism']\n",
            "['alma_mater', ' Moscow College of Art (now in the Moscow Institute of Painting, Sculpture and Architecture)']\n",
            "['awards', \" People's Artist of the USSR, Hero of Socialist Labour\"]\n",
            "['elected', \" People's Artist of Russia in 2006\"]\n",
            "['mother', ' Anastasia Nikolaevna Ivanova']\n",
            "['father', ' Nikolay Ivanovich Ivanov']\n",
            "['partner', ' Alexandra Alexandrovna Vasilieva']\n",
            "['children', ' Alexandra Ivanovna Vasilieva and Anastasia Ivanovna Vasilieva']\n",
            "['---']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How well did your model perform?"
      ],
      "metadata": {
        "id": "rCMqucECM9EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - fill in these values\n",
        "average_precision = 0.43357593943181366\n",
        "average_recall = 0.6911389522070636\n",
        "average_fscore = 0.5623574458194386\n",
        "\n",
        "# What attributes had the highest F-scorre\n",
        "best_attributes = {\n",
        "    \"BIRTH_PLACE\" : 0.7782805429864253,\n",
        "}\n",
        "\n",
        "# What attributes had the lowest F-scorre\n",
        "worst_attributes = {\n",
        "    \"HOMETOWN\" : 0.17142857142857143,\n",
        "}\n",
        "\n",
        "# What could you do the perform the model's performance?\n",
        "potential_improvements = \"\"\"\n",
        "- increase the size of training dataset\n",
        "- combine few-shot and fine-tuning\n",
        "- use more compelx base model, more complex than davinci\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O5frXHaeNFjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feedback questions"
      ],
      "metadata": {
        "id": "5NFilM6oNv-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many hours did you spend on this assignment? Just an approximation is fine.\n",
        "num_hours_spent = 8\n",
        "\n",
        "# What did you think?  This was the first time we tried this assignment\n",
        "# so you're feedback is valable.\n",
        "feedback = \"\"\"\n",
        "It was a great practice fine-tuning or prompt engineering \\\n",
        "a large pre-trained neural language model like GPT3 for a particular task of interest.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "yPS7_smBN-2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}